import os
import json
import asyncio
import time
from typing import Any, Dict, List, Optional
from dataclasses import dataclass

from dotenv import load_dotenv
from openai import AzureOpenAI, BadRequestError

from google.adk import Agent, Runner
from google.adk.tools import BaseTool
from google.adk.tools.mcp_tool.mcp_toolset import McpToolset
from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPConnectionParams

load_dotenv()


class ContentFilterError(Exception):
    """Azure OpenAI ì½˜í…ì¸  í•„í„°ë§ ì—ëŸ¬"""
    def __init__(self, filtered_categories: List[str], original_error: Exception):
        self.filtered_categories = filtered_categories
        self.original_error = original_error
        super().__init__(f"Content filtered: {', '.join(filtered_categories)}")


class AzureOpenAIWrapper:
    """Azure OpenAIë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ë˜í¼ (ADK Tool ì‹œìŠ¤í…œê³¼ í•¨ê»˜ ì‚¬ìš©)"""

    def __init__(self, api_key: str, api_version: str, azure_endpoint: str, deployment: str):
        try:
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint,
            )
            self.deployment = deployment
        except Exception as e:
            print("[AOAI] init failed ->", e)

    def chat_completion(self, messages: List[Dict[str, Any]],
                        tools: Optional[List[Dict[str, Any]]] = None,
                        stream: bool = False):
        """Azure OpenAI Chat Completion í˜¸ì¶œ"""
        try:
            return self.client.chat.completions.create(
                model=self.deployment,
                messages=messages,
                tools=tools,
                tool_choice="auto",
                temperature=0.2,
                stream=stream,
            )
        except BadRequestError as e:
            # ì½˜í…ì¸  í•„í„°ë§ ì—ëŸ¬ ì²˜ë¦¬
            error_str = str(e)
            if 'content_filter' in error_str or 'content management policy' in error_str.lower():
                error_body = getattr(e, 'body', None)
                filtered_categories = []
                if error_body and isinstance(error_body, dict):
                    error_info = error_body.get('error', {})
                    inner_error = error_info.get('innererror', {})
                    filter_result = inner_error.get('content_filter_result', {})
                    for category, details in filter_result.items():
                        if isinstance(details, dict) and details.get('filtered'):
                            severity = details.get('severity', 'unknown')
                            filtered_categories.append(f"{category}={severity}")
                if not filtered_categories:
                    filtered_categories = ['content_filter']
                raise ContentFilterError(filtered_categories=filtered_categories, original_error=e)
            raise


@dataclass
class MCPServerConnection:
    """ë‹¨ì¼ MCP ì„œë²„ ì—°ê²°ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    name: str
    toolset: McpToolset


@dataclass
class AgentResponse:
    """ì—ì´ì „íŠ¸ ì‘ë‹µ ë°ì´í„° í´ë˜ìŠ¤"""
    content: str
    metadata: Dict[str, Any]
    success: bool
    agent_name: str


class SpecializedAgent:
    """íŠ¹í™”ëœ ì—ì´ì „íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self, name: str, role: str, system_prompt: str, aoai_wrapper: AzureOpenAIWrapper):
        self.name = name
        self.role = role
        self.system_prompt = system_prompt
        self.aoai_wrapper = aoai_wrapper

    async def process(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """ì—ì´ì „íŠ¸ê°€ ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µ ë°˜í™˜"""
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_input}
        ]

        # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if context:
            context_str = f"\n\n[Context from previous agents]\n{json.dumps(context, indent=2, ensure_ascii=False)}"
            messages[-1]["content"] += context_str

        try:
            response = self.aoai_wrapper.chat_completion(messages, stream=False)
            content = response.choices[0].message.content or ""

            return AgentResponse(
                content=content,
                metadata={"tokens": response.usage.total_tokens if hasattr(response, 'usage') else 0},
                success=True,
                agent_name=self.name
            )
        except ContentFilterError as e:
            return AgentResponse(
                content=f"ì½˜í…ì¸  í•„í„°ë§ ì°¨ë‹¨: {', '.join(e.filtered_categories)}",
                metadata={"error": str(e)},
                success=False,
                agent_name=self.name
            )
        except Exception as e:
            return AgentResponse(
                content=f"ì—ëŸ¬ ë°œìƒ: {str(e)}",
                metadata={"error": str(e)},
                success=False,
                agent_name=self.name
            )


class QuestionUnderstandingAgent(SpecializedAgent):
    """Agent A: ì§ˆë¬¸ ì´í•´ ë‹´ë‹¹"""

    def __init__(self, aoai_wrapper: AzureOpenAIWrapper):
        system_prompt = """ë‹¹ì‹ ì€ ì§ˆë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì¶”ì¶œí•©ë‹ˆë‹¤:
1. í•µì‹¬ í‚¤ì›Œë“œ
2. ì§ˆë¬¸ ìœ í˜• (ë²•ë¥  ê´€ë ¨, íŒë¡€ ê²€ìƒ‰, ì¼ë°˜ ì§ˆë¬¸)
3. í•„ìš”í•œ í›„ì† ì—ì´ì „íŠ¸ (legal_agent, precedent_agent, ë˜ëŠ” none)
4. êµ¬ì¡°í™”ëœ ì¿¼ë¦¬

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:
{
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
  "question_type": "legal|precedent|general",
  "next_agent": "legal_agent|precedent_agent|none",
  "structured_query": "ì¬êµ¬ì„±ëœ ëª…í™•í•œ ì§ˆë¬¸",
  "analysis": "ê°„ë‹¨í•œ ë¶„ì„ ì„¤ëª…"
}"""
        super().__init__(
            name="QuestionUnderstandingAgent",
            role="ì§ˆë¬¸ ì´í•´ ë° ë¶„ì„",
            system_prompt=system_prompt,
            aoai_wrapper=aoai_wrapper
        )


class LegalExpertAgent(SpecializedAgent):
    """Agent B: ë²•ë¥  ì „ë¬¸"""

    def __init__(self, aoai_wrapper: AzureOpenAIWrapper, tools: List[BaseTool]):
        system_prompt = """ë‹¹ì‹ ì€ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
ê°€ëŠ¥í•œ ê²½ìš° ê´€ë ¨ ë²•ì¡°ë¬¸, ë²•ë¥  ìš©ì–´, ì ˆì°¨ ë“±ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
í•„ìš”ì‹œ ì œê³µëœ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
        super().__init__(
            name="LegalExpertAgent",
            role="ë²•ë¥  ì „ë¬¸ ë‹µë³€",
            system_prompt=system_prompt,
            aoai_wrapper=aoai_wrapper
        )
        self.tools = tools

    async def process_with_tools(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬"""
        tools_for_openai = []
        for tool in self.tools:
            tool_name = getattr(tool, 'name', type(tool).__name__)
            tool_description = getattr(tool, 'description', '')
            tool_input_schema = getattr(tool, 'input_schema', None) or {"type": "object", "properties": {}}
            tools_for_openai.append({
                "type": "function",
                "function": {
                    "name": tool_name,
                    "description": tool_description or "",
                    "parameters": tool_input_schema,
                },
            })

        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_input}
        ]

        if context:
            context_str = f"\n\n[Context]\n{json.dumps(context, indent=2, ensure_ascii=False)}"
            messages[-1]["content"] += context_str

        # ë„êµ¬ í˜¸ì¶œ ë£¨í”„
        max_iterations = 5
        for iteration in range(max_iterations):
            try:
                response = self.aoai_wrapper.chat_completion(messages, tools=tools_for_openai, stream=False)
                choice = response.choices[0].message

                if not getattr(choice, "tool_calls", None):
                    # ë„êµ¬ í˜¸ì¶œ ì—†ìŒ - ìµœì¢… ë‹µë³€
                    return AgentResponse(
                        content=choice.content or "",
                        metadata={"iterations": iteration + 1},
                        success=True,
                        agent_name=self.name
                    )

                # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
                print(f"  ğŸ”§ [{self.name}] Tool calls: {len(choice.tool_calls)}", flush=True)
                tool_results = []

                for tc in choice.tool_calls:
                    tool_name = tc.function.name
                    args = json.loads(tc.function.arguments) if tc.function.arguments else {}

                    for tool in self.tools:
                        current_tool_name = getattr(tool, 'name', type(tool).__name__)
                        if current_tool_name == tool_name:
                            try:
                                from google.adk.models import LlmRequest
                                class DummyToolContext:
                                    def __init__(self):
                                        self.llm_request = LlmRequest(contents=[])

                                tool_context = DummyToolContext()
                                result = await tool.run_async(args=args, tool_context=tool_context)
                                tool_results.append({
                                    "tool_call_id": tc.id,
                                    "content": str(result),
                                })
                                print(f"    âœ… Tool {tool_name} executed", flush=True)
                                break
                            except Exception as e:
                                tool_results.append({
                                    "tool_call_id": tc.id,
                                    "content": f"Error: {str(e)}",
                                })
                                break

                messages.append({
                    "role": "assistant",
                    "content": choice.content or "",
                    "tool_calls": [tc.model_dump() for tc in choice.tool_calls],
                })
                for tr in tool_results:
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tr["tool_call_id"],
                        "content": tr["content"],
                    })

            except Exception as e:
                return AgentResponse(
                    content=f"ì—ëŸ¬ ë°œìƒ: {str(e)}",
                    metadata={"error": str(e), "iteration": iteration},
                    success=False,
                    agent_name=self.name
                )

        return AgentResponse(
            content="ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬",
            metadata={"iterations": max_iterations},
            success=False,
            agent_name=self.name
        )


class PrecedentExpertAgent(SpecializedAgent):
    """Agent C: íŒë¡€ ì „ë¬¸"""

    def __init__(self, aoai_wrapper: AzureOpenAIWrapper, tools: List[BaseTool]):
        system_prompt = """ë‹¹ì‹ ì€ íŒë¡€ ê²€ìƒ‰ ë° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
íŒë¡€ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ íŒë¡€ë¥¼ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.
íŒë¡€ì˜ í•µì‹¬ ìŸì , íŒê²° ìš”ì§€, ì ìš© ë²•ë¦¬ ë“±ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.
í•„ìš”ì‹œ ì œê³µëœ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒë¡€ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
        super().__init__(
            name="PrecedentExpertAgent",
            role="íŒë¡€ ê²€ìƒ‰ ë° ë¶„ì„",
            system_prompt=system_prompt,
            aoai_wrapper=aoai_wrapper
        )
        self.tools = tools

    async def process_with_tools(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒë¡€ ê²€ìƒ‰ ë° ë¶„ì„"""
        # LegalExpertAgentì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©
        agent = LegalExpertAgent(self.aoai_wrapper, self.tools)
        agent.name = self.name
        agent.system_prompt = self.system_prompt
        return await agent.process_with_tools(user_input, context)


class MultiAgentOrchestrator:
    """ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - ì—¬ëŸ¬ íŠ¹í™” ì—ì´ì „íŠ¸ë¥¼ ê´€ë¦¬í•˜ê³  ì¡°ìœ¨"""

    def __init__(self):
        self.servers: Dict[str, MCPServerConnection] = {}
        self.all_tools: List[BaseTool] = []
        self._closing = False
        self.aoai_wrapper: Optional[AzureOpenAIWrapper] = None

        # íŠ¹í™”ëœ ì—ì´ì „íŠ¸ë“¤
        self.question_agent: Optional[QuestionUnderstandingAgent] = None
        self.legal_agent: Optional[LegalExpertAgent] = None
        self.precedent_agent: Optional[PrecedentExpertAgent] = None

    @staticmethod
    def _normalize_url(url: str) -> str:
        # ì„œë²„ê°€ /mcp/ ê°™ì€ íŠ¸ë ˆì¼ë§ ìŠ¬ë˜ì‹œë¥¼ ê¸°ëŒ€í•˜ëŠ” ê²½ìš° ë¦¬ë‹¤ì´ë ‰íŠ¸ ë£¨í”„ ë°©ì§€
        return url if url.endswith("/") else url + "/"

    async def connect_mcp_server(self, server_name: str, base_url: str, auth_bearer: str = "") -> MCPServerConnection:
        if self._closing:
            raise RuntimeError("Agent is closing; refuse new connections.")

        base_url = self._normalize_url(base_url)

        headers = {}
        if auth_bearer:
            headers["Authorization"] = f"Bearer {auth_bearer}"

        try:
            conn_params = StreamableHTTPConnectionParams(
                url=base_url,
                headers=headers if headers else None,
                timeout=10.0,
                sse_read_timeout=300.0,
            )
            toolset = McpToolset(connection_params=conn_params)
            tools = await toolset.get_tools()

            connection = MCPServerConnection(
                name=server_name,
                toolset=toolset
            )
            self.servers[server_name] = connection
            for tool in tools:
                self.all_tools.append(tool)

            return connection

        except Exception as e:
            error_msg = str(e)
            if "400 Bad Request" in error_msg:
                print(f"\n[Error] HTTP 400 Bad Request for {server_name}")
                print(f" URL: {base_url}")
                print(f" ê°€ëŠ¥í•œ ì›ì¸:")
                print(f" - URLì´ ì˜¬ë°”ë¥´ì§€ ì•Šê±°ë‚˜ ì—”ë“œí¬ì¸íŠ¸ê°€ ë‹¤ë¦„")
                print(f" - ì¸ì¦ í† í°ì´ í•„ìš”í•˜ê±°ë‚˜ ì˜ëª»ë¨ (í˜„ì¬ bearer: {'ì„¤ì •ë¨' if auth_bearer else 'ì—†ìŒ'})")
                print(f" - ì„œë²„ê°€ í•´ë‹¹ ê²½ë¡œë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ")
            elif "Connection" in error_msg or "connect" in error_msg.lower():
                print(f"\n[Error] Connection failed for {server_name}")
                print(f" URL: {base_url}")
                print(f" ê°€ëŠ¥í•œ ì›ì¸: ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ë˜ëŠ” ì„œë²„ê°€ ë‹¤ìš´ë¨")
            else:
                print(f"\n[Error] Failed to connect to {server_name}: {error_msg}")
                print(f" URL: {base_url}")
            if server_name in self.servers:
                del self.servers[server_name]
            raise RuntimeError(f"Failed to connect to MCP server {server_name} at {base_url}: {error_msg}") from e

    def initialize_agents(self):
        """ê°œë³„ íŠ¹í™” ì—ì´ì „íŠ¸ë“¤ì„ ì´ˆê¸°í™”"""
        self.aoai_wrapper = AzureOpenAIWrapper(
            api_key=os.environ["AZURE_OPENAI_API_KEY"],
            api_version=os.environ["AZURE_OPENAI_API_VERSION"],
            azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
            deployment=os.environ["AZURE_OPENAI_DEPLOYMENT"],
        )

        # Agent A: ì§ˆë¬¸ ì´í•´ ë‹´ë‹¹
        self.question_agent = QuestionUnderstandingAgent(self.aoai_wrapper)

        # Agent B: ë²•ë¥  ì „ë¬¸ (MCP Server 1 ë„êµ¬ ì‚¬ìš©)
        legal_tools = [tool for tool in self.all_tools if 'mcp1' in getattr(tool, 'name', '')]
        self.legal_agent = LegalExpertAgent(self.aoai_wrapper, legal_tools if legal_tools else self.all_tools)

        # Agent C: íŒë¡€ ì „ë¬¸ (MCP Server 2 ë„êµ¬ ì‚¬ìš©)
        precedent_tools = [tool for tool in self.all_tools if 'mcp2' in getattr(tool, 'name', '')]
        self.precedent_agent = PrecedentExpertAgent(self.aoai_wrapper, precedent_tools if precedent_tools else self.all_tools)

        print(f"âœ… ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ:")
        print(f"   - {self.question_agent.name}: {self.question_agent.role}")
        print(f"   - {self.legal_agent.name}: {self.legal_agent.role} (ë„êµ¬ {len(self.legal_agent.tools)}ê°œ)")
        print(f"   - {self.precedent_agent.name}: {self.precedent_agent.role} (ë„êµ¬ {len(self.precedent_agent.tools)}ê°œ)")

    async def close_all_servers(self):
        """ëª¨ë“  MCP ì„œë²„ ì—°ê²°ì„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ"""
        self._closing = True
        async def _safe_close(name: str, ts: McpToolset):
            try:
                await asyncio.wait_for(ts.close(), timeout=8.0)
                print(f"âœ“ Closed {name}")
            except asyncio.TimeoutError:
                print(f"âš ï¸  Timeout closing server {name} (forced close)")
            except asyncio.CancelledError:
                print(f"âš ï¸  Cancelled while closing server {name}")
            except Exception as e:
                print(f"âš ï¸  Error closing server {name}: {e}")
        # ìˆœì°¨ ì¢…ë£Œ
        for name, srv in list(self.servers.items()):
            if srv.toolset:
                await _safe_close(name, srv.toolset)
        self.servers.clear()
        self.all_tools.clear()
        self._closing = False


async def initialize_multi_agent() -> MultiAgentOrchestrator:
    """ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    orchestrator = MultiAgentOrchestrator()

    mcp1_connected = False
    mcp2_connected = False

    try:
        mcp1_url = os.environ.get("MCP_SERVER_1_URL", "")
        mcp1_bearer = os.environ.get("MCP_SERVER_1_AUTH_BEARER", "")
        if mcp1_url:
            print(f"Connecting to MCP Server 1 (ë²•ë¥  ë„êµ¬): {mcp1_url}")
            try:
                await orchestrator.connect_mcp_server("mcp1", mcp1_url, mcp1_bearer)
                print("âœ“ Connected to MCP Server 1")
                mcp1_connected = True
            except Exception as e:
                print(f"âœ— Failed to connect to MCP Server 1: {e}")
        else:
            raise RuntimeError("MCP_SERVER_1_URL í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        mcp2_url = os.environ.get("MCP_SERVER_2_URL", "")
        mcp2_bearer = os.environ.get("MCP_SERVER_2_AUTH_BEARER", "")
        if mcp2_url:
            print(f"Connecting to MCP Server 2 (íŒë¡€ ë„êµ¬): {mcp2_url}")
            try:
                await orchestrator.connect_mcp_server("mcp2", mcp2_url, mcp2_bearer)
                print("âœ“ Connected to MCP Server 2")
                mcp2_connected = True
            except Exception as e:
                print(f"âœ— Failed to connect to MCP Server 2: {e}")
        else:
            raise RuntimeError("MCP_SERVER_2_URL í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        if not mcp1_connected and not mcp2_connected:
            raise RuntimeError("Both MCP servers failed to connect. At least one server must be connected.")

        if not mcp1_connected:
            print("âš  Warning: MCP Server 1 is not connected, continuing with Server 2 only.")
        if not mcp2_connected:
            print("âš  Warning: MCP Server 2 is not connected, continuing with Server 1 only.")

        print("\nInitializing Multi-Agent System...")
        orchestrator.initialize_agents()
        print(f"âœ“ Multi-Agent System initialized with {len(orchestrator.all_tools)} total tools\n")

        return orchestrator

    except Exception as e:
        raise RuntimeError(f"Failed to initialize multi-agent system: {e}") from e


async def run_multi_agent_conversation(orchestrator: MultiAgentOrchestrator, user_query: str) -> str:
    """ë©€í‹° ì—ì´ì „íŠ¸ ëŒ€í™” ì‹¤í–‰: Agent A â†’ Agent B/C"""

    print(f"\n{'='*60}")
    print(f"ğŸ¤– Multi-Agent Processing Pipeline")
    print(f"{'='*60}\n")

    # Step 1: Agent A - ì§ˆë¬¸ ì´í•´
    print(f"ğŸ“‹ [Step 1] Agent A: ì§ˆë¬¸ ë¶„ì„")
    print(f"â”€" * 60)

    step1_start = time.time()
    question_response = await orchestrator.question_agent.process(user_query)
    step1_time = time.time() - step1_start

    if not question_response.success:
        print(f"âŒ ì§ˆë¬¸ ë¶„ì„ ì‹¤íŒ¨: {question_response.content}")
        return question_response.content

    print(f"âœ… ë¶„ì„ ì™„ë£Œ ({step1_time:.2f}ì´ˆ)")
    print(f"\n{question_response.content}\n")

    # JSON íŒŒì‹± ì‹œë„
    try:
        # JSON ì¶”ì¶œ (```json ... ``` í˜•ì‹ë„ ì²˜ë¦¬)
        content = question_response.content
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()

        analysis = json.loads(content)
        next_agent = analysis.get("next_agent", "none")
        question_type = analysis.get("question_type", "general")
        structured_query = analysis.get("structured_query", user_query)

        print(f"ğŸ¯ íŒë‹¨ ê²°ê³¼:")
        print(f"   ì§ˆë¬¸ ìœ í˜•: {question_type}")
        print(f"   ë‹¤ìŒ ì—ì´ì „íŠ¸: {next_agent}")
        print(f"   êµ¬ì¡°í™”ëœ ì¿¼ë¦¬: {structured_query}\n")

    except json.JSONDecodeError:
        print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ ì²˜ë¦¬ë¡œ ì§„í–‰\n")
        next_agent = "legal_agent"  # ê¸°ë³¸ê°’
        structured_query = user_query

    # Step 2: Agent B ë˜ëŠ” Cë¡œ ë¼ìš°íŒ…
    if next_agent == "none" or next_agent not in ["legal_agent", "precedent_agent"]:
        print(f"ğŸ’¬ [Final Answer] ì¶”ê°€ ì²˜ë¦¬ ë¶ˆí•„ìš”")
        return question_response.content

    # Step 2: ì „ë¬¸ ì—ì´ì „íŠ¸ ì²˜ë¦¬
    if next_agent == "legal_agent":
        print(f"âš–ï¸  [Step 2] Agent B: ë²•ë¥  ì „ë¬¸ê°€ ì²˜ë¦¬")
        print(f"â”€" * 60)
        specialist_agent = orchestrator.legal_agent
    else:  # precedent_agent
        print(f"ğŸ“š [Step 2] Agent C: íŒë¡€ ì „ë¬¸ê°€ ì²˜ë¦¬")
        print(f"â”€" * 60)
        specialist_agent = orchestrator.precedent_agent

    step2_start = time.time()

    # ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
    context = {
        "original_query": user_query,
        "analysis": question_response.content,
        "structured_query": structured_query
    }

    final_response = await specialist_agent.process_with_tools(structured_query, context)
    step2_time = time.time() - step2_start

    if not final_response.success:
        print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {final_response.content}")
        return final_response.content

    print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ ({step2_time:.2f}ì´ˆ)")

    # Step 3: ìµœì¢… ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
    print(f"\nğŸ’¬ [Final Answer] ")
    print(f"â”€" * 60)

    # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ì¶œë ¥
    try:
        messages = [
            {"role": "system", "content": "ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”. ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”."},
            {"role": "user", "content": f"ì›ë³¸ ì§ˆë¬¸: {user_query}\n\në¶„ì„ ê²°ê³¼:\n{question_response.content}\n\nì „ë¬¸ê°€ ë‹µë³€:\n{final_response.content}"}
        ]

        stream_start = time.time()
        stream_response = orchestrator.aoai_wrapper.chat_completion(messages, stream=True)

        collected_content = ""
        for chunk in stream_response:
            if chunk.choices and len(chunk.choices) > 0:
                delta = chunk.choices[0].delta
                if hasattr(delta, 'content') and delta.content:
                    print(delta.content, end="", flush=True)
                    collected_content += delta.content

        stream_time = time.time() - stream_start
        print(f"\n\nâ±ï¸  ìŠ¤íŠ¸ë¦¬ë° ì‹œê°„: {stream_time:.2f}ì´ˆ")

        return collected_content

    except ContentFilterError as e:
        print(f"\nğŸš« ì½˜í…ì¸  í•„í„°ë§ ì°¨ë‹¨: {', '.join(e.filtered_categories)}")
        return final_response.content
    except Exception as e:
        print(f"\nâš ï¸  ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µ ë°˜í™˜: {e}")
        return final_response.content
    if not agent.agent or not agent.aoai_wrapper:
        raise RuntimeError("Agent not initialized")

    tools_for_openai = []
    for tool in agent.all_tools:
        tool_name = getattr(tool, 'name', type(tool).__name__)
        tool_description = getattr(tool, 'description', '')
        tool_input_schema = getattr(tool, 'input_schema', None) or {"type": "object", "properties": {}}
        tools_for_openai.append({
            "type": "function",
            "function": {
                "name": tool_name,
                "description": tool_description or "",
                "parameters": tool_input_schema,
            },
        })

    messages: List[Dict[str, Any]] = [
        {
            "role": "system",
            "content": (
                "You are a super agent that can use tools from multiple MCP servers. "
                "Tool names are prefixed with server names (e.g., 'mcp1__tool_name' or 'mcp2__tool_name'). "
                "Use the appropriate tools from different servers to help the user."
            )
        },
        {"role": "user", "content": user_query},
    ]

    iteration = 0

    while iteration < max_iterations:
        iteration += 1
        print(f"\n[Iteration {iteration}]", flush=True)

        inference_start = time.time()
        try:
            response = agent.aoai_wrapper.chat_completion(messages, tools=tools_for_openai, stream=False)
            choice = response.choices[0].message
            inference_time = time.time() - inference_start
            print(f"â±ï¸  ì¶”ë¡  ì‹œê°„: {inference_time:.2f}ì´ˆ", flush=True)
        except ContentFilterError as e:
            print(f"\nğŸš« ì½˜í…ì¸  í•„í„°ë§ ì°¨ë‹¨: {', '.join(e.filtered_categories)}", flush=True)
            print(f"ğŸ’¡ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”.", flush=True)
            return "ìš”ì²­ì´ ì½˜í…ì¸  ì •ì±…ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."
        except BadRequestError as e:
            print(f"\nâŒ API ì˜¤ë¥˜: {str(e)}", flush=True)
            return f"ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"

        # ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš°
        if getattr(choice, "tool_calls", None):
            print(f"\nğŸ”§ [TOOL CALL DETECTED] count = {len(choice.tool_calls)}", flush=True)

            tool_results: List[Dict[str, Any]] = []
            for tc in choice.tool_calls:
                print(f"  â”œâ”€ Tool name : {tc.function.name}", flush=True)
                print(f"  â”œâ”€ Args      : {tc.function.arguments}", flush=True)
                print(f"  â””â”€ Call ID   : {tc.id}", flush=True)

                tool_name = tc.function.name
                args = json.loads(tc.function.arguments) if tc.function.arguments else {}
                tool_found = False

                tool_start = time.time()
                for tool in agent.all_tools:
                    current_tool_name = getattr(tool, 'name', type(tool).__name__)
                    if current_tool_name == tool_name:
                        try:
                            from google.adk.models import LlmRequest
                            class DummyToolContext:
                                def __init__(self):
                                    self.llm_request = LlmRequest(contents=[])

                            tool_context = DummyToolContext()
                            result = await tool.run_async(args=args, tool_context=tool_context)
                            tool_time = time.time() - tool_start
                            print(f"  âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ ({tool_time:.2f}ì´ˆ)", flush=True)

                            tool_results.append({
                                "tool_call_id": tc.id,
                                "content": str(result),
                            })
                            tool_found = True
                            break
                        except Exception as e:
                            tool_time = time.time() - tool_start
                            print(f"  âŒ ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ ({tool_time:.2f}ì´ˆ): {str(e)}", flush=True)
                            tool_results.append({
                                "tool_call_id": tc.id,
                                "content": f"Error: {str(e)}",
                            })
                            tool_found = True
                            break

                if not tool_found:
                    tool_results.append({
                        "tool_call_id": tc.id,
                        "content": f"Tool {tool_name} not found",
                    })

            messages.append({
                "role": "assistant",
                "content": choice.content or "",
                "tool_calls": [tc.model_dump() for tc in choice.tool_calls],
            })
            for tr in tool_results:
                messages.append({
                    "role": "tool",
                    "tool_call_id": tr["tool_call_id"],
                    "content": tr["content"],
                })

        else:
            # ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ì¶œë ¥
            print("\nğŸ’¬ [Assistant] ", end="", flush=True)
            try:
                stream_start = time.time()
                stream_response = agent.aoai_wrapper.chat_completion(messages, tools=tools_for_openai, stream=True)

                collected_content = ""
                for chunk in stream_response:
                    if chunk.choices and len(chunk.choices) > 0:
                        delta = chunk.choices[0].delta
                        if hasattr(delta, 'content') and delta.content:
                            print(delta.content, end="", flush=True)
                            collected_content += delta.content

                stream_time = time.time() - stream_start
                print(f"\nâ±ï¸  ìŠ¤íŠ¸ë¦¬ë° ì‹œê°„: {stream_time:.2f}ì´ˆ", flush=True)

                final_answer = collected_content or choice.content or "(no content)"
                return final_answer
            except ContentFilterError as e:
                print(f"\n\nğŸš« ì½˜í…ì¸  í•„í„°ë§ ì°¨ë‹¨: {', '.join(e.filtered_categories)}", flush=True)
                return "ì‘ë‹µì´ ì½˜í…ì¸  ì •ì±…ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."
            except BadRequestError as e:
                print(f"\n\nâŒ API ì˜¤ë¥˜: {str(e)}", flush=True)
                return f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}"

    return "Maximum iterations reached."


async def main():
    print("=" * 60)
    print("Super Agent: Google ADK + 2 MCP Servers + Azure OpenAI")
    print("=" * 60)
    agent = None
    try:
        agent = await initialize_super_agent()
        print("\nâœ… Super Agent is ready!")
        print("Type 'quit' or 'exit' to stop.\n")
        while True:
            q = input("\nğŸ§‘ You> ").strip()
            if q.lower() in {"quit", "exit", "q"}:
                break
            if not q:
                continue
            try:
                conversation_start = time.time()
                ans = await run_conversation(agent, q)
                total_time = time.time() - conversation_start
                print(f"\nâ±ï¸  ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
            except (ContentFilterError, BadRequestError):
                pass
            except Exception as e:
                print(f"\nâŒ [Error] {e}")
                import traceback
                traceback.print_exc()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Interrupted by user.")
    except Exception as e:
        print(f"\nâŒ [Fatal Error] {e}")
        import traceback
        traceback.print_exc()
    finally:
        if agent:
            print("\nğŸ”Œ Closing all MCP server connections...")
            try:
                await agent.close_all_servers()
                print("âœ“ All connections closed.")
            except asyncio.CancelledError:
                print("âš ï¸  Connection cleanup was cancelled")
            except Exception as e:
                print(f"âš ï¸  Error during cleanup: {e}")


if __name__ == "__main__":
    asyncio.run(main())

