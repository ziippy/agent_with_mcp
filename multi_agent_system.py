import os
import json
import asyncio
import time
from typing import Any, Dict, List, Optional
from dataclasses import dataclass

from dotenv import load_dotenv
from openai import AzureOpenAI, BadRequestError

from google.adk.tools import BaseTool
from google.adk.tools.mcp_tool.mcp_toolset import McpToolset
from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPConnectionParams

load_dotenv()


class ContentFilterError(Exception):
    """Azure OpenAI ÏΩòÌÖêÏ∏† ÌïÑÌÑ∞ÎßÅ ÏóêÎü¨"""
    def __init__(self, filtered_categories: List[str], original_error: Exception):
        self.filtered_categories = filtered_categories
        self.original_error = original_error
        super().__init__(f"Content filtered: {', '.join(filtered_categories)}")


class AzureOpenAIWrapper:
    """Azure OpenAI ÎûòÌçº"""

    def __init__(self, api_key: str, api_version: str, azure_endpoint: str, deployment: str):
        try:
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint,
            )
            self.deployment = deployment
        except Exception as e:
            print("[AOAI] init failed ->", e)

    def chat_completion(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]] = None, stream: bool = False):
        """Azure OpenAI Chat Completion Ìò∏Ï∂ú"""
        try:
            # toolsÍ∞Ä ÏûàÏùÑ ÎïåÎßå tool_choice ÏÑ§Ï†ï
            kwargs = {
                "model": self.deployment,
                "messages": messages,
                "temperature": 0.2,
                "stream": stream,
            }

            if tools:
                kwargs["tools"] = tools
                kwargs["tool_choice"] = "auto"

            return self.client.chat.completions.create(**kwargs)
        except BadRequestError as e:
            error_str = str(e)

            if 'content_filter' in error_str or 'content management policy' in error_str.lower():
                error_body = getattr(e, 'body', None)
                filtered_categories = []

                if error_body and isinstance(error_body, dict):
                    error_info = error_body.get('error', {})
                    inner_error = error_info.get('innererror', {})
                    filter_result = inner_error.get('content_filter_result', {})

                    for category, details in filter_result.items():
                        if isinstance(details, dict) and details.get('filtered'):
                            severity = details.get('severity', 'unknown')
                            filtered_categories.append(f"{category}={severity}")

                if not filtered_categories:
                    filtered_categories = ['content_filter']

                raise ContentFilterError(
                    filtered_categories=filtered_categories,
                    original_error=e
                )

            raise


@dataclass
class MCPServerConnection:
    """Îã®Ïùº MCP ÏÑúÎ≤Ñ Ïó∞Í≤∞"""
    name: str
    toolset: McpToolset


@dataclass
class AgentResponse:
    """ÏóêÏù¥Ï†ÑÌä∏ ÏùëÎãµ"""
    content: str
    metadata: Dict[str, Any]
    success: bool
    agent_name: str


class SpecializedAgent:
    """ÌäπÌôîÎêú ÏóêÏù¥Ï†ÑÌä∏ Í∏∞Î≥∏ ÌÅ¥ÎûòÏä§"""

    def __init__(self, name: str, role: str, system_prompt: str, aoai_wrapper: AzureOpenAIWrapper):
        self.name = name
        self.role = role
        self.system_prompt = system_prompt
        self.aoai_wrapper = aoai_wrapper

    async def process(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """ÏóêÏù¥Ï†ÑÌä∏ Ï≤òÎ¶¨"""
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_input}
        ]

        if context:
            context_str = f"\n\n[Context from previous agents]\n{json.dumps(context, indent=2, ensure_ascii=False)}"
            messages[-1]["content"] += context_str

        try:
            response = self.aoai_wrapper.chat_completion(messages, stream=False)
            content = response.choices[0].message.content or ""

            return AgentResponse(
                content=content,
                metadata={"tokens": response.usage.total_tokens if hasattr(response, 'usage') else 0},
                success=True,
                agent_name=self.name
            )
        except ContentFilterError as e:
            return AgentResponse(
                content=f"ÏΩòÌÖêÏ∏† ÌïÑÌÑ∞ÎßÅ Ï∞®Îã®: {', '.join(e.filtered_categories)}",
                metadata={"error": str(e)},
                success=False,
                agent_name=self.name
            )
        except Exception as e:
            return AgentResponse(
                content=f"ÏóêÎü¨ Î∞úÏÉù: {str(e)}",
                metadata={"error": str(e)},
                success=False,
                agent_name=self.name
            )


class QuestionUnderstandingAgent(SpecializedAgent):
    """Agent A: ÏßàÎ¨∏ Ïù¥Ìï¥ Îã¥Îãπ"""

    def __init__(self, aoai_wrapper: AzureOpenAIWrapper):
        system_prompt = """ÎãπÏã†ÏùÄ ÏßàÎ¨∏ Î∂ÑÏÑù Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.
ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏ÏùÑ Î∂ÑÏÑùÌïòÏó¨ Îã§ÏùåÏùÑ Ï∂îÏ∂úÌï©ÎãàÎã§:
1. ÌïµÏã¨ ÌÇ§ÏõåÎìú
2. ÏßàÎ¨∏ Ïú†Ìòï (Î≤ïÎ•†+ÌåêÎ°Ä Î≥µÌï©, Î≤ïÎ•†Îßå, ÌåêÎ°ÄÎßå, ÏùºÎ∞ò)
3. ÌïÑÏöîÌïú ÌõÑÏÜç ÏóêÏù¥Ï†ÑÌä∏Îì§ (Î∞∞Ïó¥Î°ú Î≥µÏàò ÏÑ†ÌÉù Í∞ÄÎä•)
4. Í∞Å ÏóêÏù¥Ï†ÑÌä∏Î≥Ñ Íµ¨Ï°∞ÌôîÎêú ÏøºÎ¶¨

ÏùëÎãµÏùÄ Î∞òÎìúÏãú Îã§Ïùå JSON ÌòïÏãùÏúºÎ°ú Ï†úÍ≥µÌïòÏÑ∏Ïöî:
{
  "keywords": ["ÌÇ§ÏõåÎìú1", "ÌÇ§ÏõåÎìú2"],
  "question_type": "legal_and_precedent|legal_only|precedent_only|general",
  "next_agents": ["legal_agent", "precedent_agent"] or ["legal_agent"] or ["precedent_agent"] or [],
  "queries": {
    "legal_agent": "Î≤ïÎ•† ÏóêÏù¥Ï†ÑÌä∏ÏóêÍ≤å Ìï† ÏßàÎ¨∏ (Ìï¥ÎãπÎêòÎäî Í≤ΩÏö∞)",
    "precedent_agent": "ÌåêÎ°Ä ÏóêÏù¥Ï†ÑÌä∏ÏóêÍ≤å Ìï† ÏßàÎ¨∏ (Ìï¥ÎãπÎêòÎäî Í≤ΩÏö∞)"
  },
  "analysis": "Í∞ÑÎã®Ìïú Î∂ÑÏÑù ÏÑ§Î™Ö"
}

ÏòàÏãú:
- "Ï§ëÎåÄÏû¨Ìï¥Ï≤òÎ≤åÎ≤ï + ÏµúÍ∑º ÏÇ¨Î°Ä" ‚Üí next_agents: ["legal_agent", "precedent_agent"]
- "Í≥ÑÏïΩÎ≤ï Ï°∞Ìï≠" ‚Üí next_agents: ["legal_agent"]
- "Î∂ÄÎãπÌï¥Í≥† ÌåêÎ°Ä" ‚Üí next_agents: ["precedent_agent"]"""
        super().__init__(
            name="QuestionUnderstandingAgent",
            role="ÏßàÎ¨∏ Ïù¥Ìï¥ Î∞è Î∂ÑÏÑù",
            system_prompt=system_prompt,
            aoai_wrapper=aoai_wrapper
        )


class LegalExpertAgent(SpecializedAgent):
    """Agent B: Î≤ïÎ•† Ï†ÑÎ¨∏"""

    def __init__(self, aoai_wrapper: AzureOpenAIWrapper, tools: List[BaseTool]):
        system_prompt = """ÎãπÏã†ÏùÄ Î≤ïÎ•† Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.
Î≤ïÎ•† Í¥ÄÎ†® ÏßàÎ¨∏Ïóê ÎåÄÌï¥ Ï†ïÌôïÌïòÍ≥† Ï†ÑÎ¨∏Ï†ÅÏù∏ ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§.
Í∞ÄÎä•Ìïú Í≤ΩÏö∞ Í¥ÄÎ†® Î≤ïÏ°∞Î¨∏, Î≤ïÎ•† Ïö©Ïñ¥, Ï†àÏ∞® Îì±ÏùÑ ÏÑ§Î™ÖÌï©ÎãàÎã§.
ÌïÑÏöîÏãú Ï†úÍ≥µÎêú ÎèÑÍµ¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ Ï†ïÎ≥¥Î•º Í≤ÄÏÉâÌï† Ïàò ÏûàÏäµÎãàÎã§."""
        super().__init__(
            name="LegalExpertAgent",
            role="Î≤ïÎ•† Ï†ÑÎ¨∏ ÎãµÎ≥Ä",
            system_prompt=system_prompt,
            aoai_wrapper=aoai_wrapper
        )
        self.tools = tools

    async def process_with_tools(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """ÎèÑÍµ¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ Ï≤òÎ¶¨"""
        tools_for_openai = []
        for tool in self.tools:
            tool_name = getattr(tool, 'name', type(tool).__name__)
            tool_description = getattr(tool, 'description', '')
            tool_input_schema = getattr(tool, 'input_schema', None) or {"type": "object", "properties": {}}
            tools_for_openai.append({
                "type": "function",
                "function": {
                    "name": tool_name,
                    "description": tool_description or "",
                    "parameters": tool_input_schema,
                },
            })

        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_input}
        ]

        if context:
            context_str = f"\n\n[Context]\n{json.dumps(context, indent=2, ensure_ascii=False)}"
            messages[-1]["content"] += context_str

        max_iterations = 5
        for iteration in range(max_iterations):
            try:
                response = self.aoai_wrapper.chat_completion(messages, tools=tools_for_openai, stream=False)
                choice = response.choices[0].message

                if not getattr(choice, "tool_calls", None):
                    return AgentResponse(
                        content=choice.content or "",
                        metadata={"iterations": iteration + 1},
                        success=True,
                        agent_name=self.name
                    )

                print(f"  üîß [{self.name}] Tool calls: {len(choice.tool_calls)}", flush=True)
                tool_results = []

                for tc in choice.tool_calls:
                    tool_name = tc.function.name
                    args = json.loads(tc.function.arguments) if tc.function.arguments else {}

                    for tool in self.tools:
                        current_tool_name = getattr(tool, 'name', type(tool).__name__)
                        if current_tool_name == tool_name:
                            try:
                                from google.adk.models import LlmRequest
                                class DummyToolContext:
                                    def __init__(self):
                                        self.llm_request = LlmRequest(contents=[])

                                tool_context = DummyToolContext()
                                result = await tool.run_async(args=args, tool_context=tool_context)
                                tool_results.append({
                                    "tool_call_id": tc.id,
                                    "content": str(result),
                                })
                                print(f"    ‚úÖ Tool {tool_name} executed", flush=True)
                                break
                            except Exception as e:
                                tool_results.append({
                                    "tool_call_id": tc.id,
                                    "content": f"Error: {str(e)}",
                                })
                                break

                messages.append({
                    "role": "assistant",
                    "content": choice.content or "",
                    "tool_calls": [tc.model_dump() for tc in choice.tool_calls],
                })
                for tr in tool_results:
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tr["tool_call_id"],
                        "content": tr["content"],
                    })

            except Exception as e:
                return AgentResponse(
                    content=f"ÏóêÎü¨ Î∞úÏÉù: {str(e)}",
                    metadata={"error": str(e), "iteration": iteration},
                    success=False,
                    agent_name=self.name
                )

        return AgentResponse(
            content="ÏµúÎåÄ Î∞òÎ≥µ ÌöüÏàò ÎèÑÎã¨",
            metadata={"iterations": max_iterations},
            success=False,
            agent_name=self.name
        )


class PrecedentExpertAgent(LegalExpertAgent):
    """Agent C: ÌåêÎ°Ä Ï†ÑÎ¨∏"""

    def __init__(self, aoai_wrapper: AzureOpenAIWrapper, tools: List[BaseTool]):
        system_prompt = """ÎãπÏã†ÏùÄ ÌåêÎ°Ä Í≤ÄÏÉâ Î∞è Î∂ÑÏÑù Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.
ÌåêÎ°Ä Í¥ÄÎ†® ÏßàÎ¨∏Ïóê ÎåÄÌï¥ Í¥ÄÎ†® ÌåêÎ°ÄÎ•º Í≤ÄÏÉâÌïòÍ≥† Î∂ÑÏÑùÌï©ÎãàÎã§.
ÌåêÎ°ÄÏùò ÌïµÏã¨ ÏüÅÏ†ê, ÌåêÍ≤∞ ÏöîÏßÄ, Ï†ÅÏö© Î≤ïÎ¶¨ Îì±ÏùÑ Î™ÖÌôïÌïòÍ≤å ÏÑ§Î™ÖÌï©ÎãàÎã§.
ÌïÑÏöîÏãú Ï†úÍ≥µÎêú ÎèÑÍµ¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÌåêÎ°ÄÎ•º Í≤ÄÏÉâÌï† Ïàò ÏûàÏäµÎãàÎã§."""
        SpecializedAgent.__init__(
            self,
            name="PrecedentExpertAgent",
            role="ÌåêÎ°Ä Í≤ÄÏÉâ Î∞è Î∂ÑÏÑù",
            system_prompt=system_prompt,
            aoai_wrapper=aoai_wrapper
        )
        self.tools = tools


class MultiAgentOrchestrator:
    """Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞"""

    def __init__(self):
        self.servers: Dict[str, MCPServerConnection] = {}
        self.all_tools: List[BaseTool] = []
        self.aoai_wrapper: Optional[AzureOpenAIWrapper] = None

        self.question_agent: Optional[QuestionUnderstandingAgent] = None
        self.legal_agent: Optional[LegalExpertAgent] = None
        self.precedent_agent: Optional[PrecedentExpertAgent] = None

    async def connect_mcp_server(self, server_name: str, base_url: str, auth_bearer: str = "") -> MCPServerConnection:
        headers = {}
        if auth_bearer:
            headers["Authorization"] = f"Bearer {auth_bearer}"
        try:
            conn_params = StreamableHTTPConnectionParams(
                url=base_url,
                headers=headers if headers else None,
                timeout=10.0,
                sse_read_timeout=300.0,
            )
            toolset = McpToolset(connection_params=conn_params)
            tools = await toolset.get_tools()
            connection = MCPServerConnection(
                name=server_name,
                toolset=toolset
            )
            self.servers[server_name] = connection
            for tool in tools:
                self.all_tools.append(tool)
            return connection
        except Exception as e:
            error_msg = str(e)
            print(f"\n[Error] Failed to connect to {server_name}: {error_msg}")
            print(f" URL: {base_url}")
            if server_name in self.servers:
                del self.servers[server_name]
            raise RuntimeError(f"Failed to connect to MCP server {server_name} at {base_url}: {error_msg}") from e

    def initialize_agents(self):
        """Í∞úÎ≥Ñ ÌäπÌôî ÏóêÏù¥Ï†ÑÌä∏Îì§ÏùÑ Ï¥àÍ∏∞Ìôî"""
        self.aoai_wrapper = AzureOpenAIWrapper(
            api_key=os.environ["AZURE_OPENAI_API_KEY"],
            api_version=os.environ["AZURE_OPENAI_API_VERSION"],
            azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
            deployment=os.environ["AZURE_OPENAI_DEPLOYMENT"],
        )

        self.question_agent = QuestionUnderstandingAgent(self.aoai_wrapper)

        legal_tools = [tool for tool in self.all_tools if 'mcp1' in getattr(tool, 'name', '')]
        self.legal_agent = LegalExpertAgent(self.aoai_wrapper, legal_tools if legal_tools else self.all_tools)

        precedent_tools = [tool for tool in self.all_tools if 'mcp2' in getattr(tool, 'name', '')]
        self.precedent_agent = PrecedentExpertAgent(self.aoai_wrapper, precedent_tools if precedent_tools else self.all_tools)

        print(f"\n‚úÖ ÏóêÏù¥Ï†ÑÌä∏ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å:")
        print(f"   ‚Ä¢ {self.question_agent.name}: {self.question_agent.role}")
        print(f"   ‚Ä¢ {self.legal_agent.name}: {self.legal_agent.role} (ÎèÑÍµ¨ {len(self.legal_agent.tools)}Í∞ú)")
        print(f"   ‚Ä¢ {self.precedent_agent.name}: {self.precedent_agent.role} (ÎèÑÍµ¨ {len(self.precedent_agent.tools)}Í∞ú)")

    async def close_all_servers(self):
        """Î™®Îì† MCP ÏÑúÎ≤Ñ Ïó∞Í≤∞ Ï¢ÖÎ£å"""
        for server_name, server in list(self.servers.items()):
            try:
                if server.toolset:
                    await asyncio.wait_for(server.toolset.close(), timeout=5.0)
                    print(f"‚úì Closed {server_name}")
            except asyncio.TimeoutError:
                print(f"‚ö†Ô∏è  Timeout closing server {server_name}")
            except asyncio.CancelledError:
                print(f"‚ö†Ô∏è  Cancelled while closing server {server_name}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Error closing server {server_name}: {e}")
        self.servers.clear()
        self.all_tools.clear()


async def initialize_multi_agent() -> MultiAgentOrchestrator:
    """Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî"""
    orchestrator = MultiAgentOrchestrator()
    mcp1_connected = False
    mcp2_connected = False

    try:
        mcp1_url = os.environ.get("MCP_SERVER_1_URL", "")
        mcp1_bearer = os.environ.get("MCP_SERVER_1_AUTH_BEARER", "")
        if mcp1_url:
            print(f"Connecting to MCP Server 1 (Î≤ïÎ•† ÎèÑÍµ¨): {mcp1_url}")
            try:
                await orchestrator.connect_mcp_server("mcp1", mcp1_url, mcp1_bearer)
                print("‚úì Connected to MCP Server 1")
                mcp1_connected = True
            except Exception as e:
                print(f"‚úó Failed to connect to MCP Server 1: {e}")

        mcp2_url = os.environ.get("MCP_SERVER_2_URL", "")
        mcp2_bearer = os.environ.get("MCP_SERVER_2_AUTH_BEARER", "")
        if mcp2_url:
            print(f"Connecting to MCP Server 2 (ÌåêÎ°Ä ÎèÑÍµ¨): {mcp2_url}")
            try:
                await orchestrator.connect_mcp_server("mcp2", mcp2_url, mcp2_bearer)
                print("‚úì Connected to MCP Server 2")
                mcp2_connected = True
            except Exception as e:
                print(f"‚úó Failed to connect to MCP Server 2: {e}")

        if not mcp1_connected and not mcp2_connected:
            raise RuntimeError("Both MCP servers failed to connect.")

        print("\nInitializing Multi-Agent System...")
        orchestrator.initialize_agents()
        print(f"‚úì Multi-Agent System initialized with {len(orchestrator.all_tools)} total tools\n")

        return orchestrator

    except Exception as e:
        raise RuntimeError(f"Failed to initialize multi-agent system: {e}") from e


async def run_multi_agent_conversation(orchestrator: MultiAgentOrchestrator, user_query: str) -> str:
    """Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÎåÄÌôî Ïã§Ìñâ: Agent A ‚Üí Agent B and/or C ‚Üí Agent A (ÌÜµÌï©)"""

    print(f"\n{'='*70}")
    print(f"ü§ñ Multi-Agent Processing Pipeline")
    print(f"{'='*70}\n")

    # Step 1: Agent A - ÏßàÎ¨∏ Î∂ÑÏÑù
    print(f"üìã [Step 1] Agent A: ÏßàÎ¨∏ Î∂ÑÏÑù")
    print(f"{'‚îÄ'*70}")

    step1_start = time.time()
    question_response = await orchestrator.question_agent.process(user_query)
    step1_time = time.time() - step1_start

    if not question_response.success:
        print(f"‚ùå ÏßàÎ¨∏ Î∂ÑÏÑù Ïã§Ìå®: {question_response.content}")
        return question_response.content

    print(f"‚úÖ Î∂ÑÏÑù ÏôÑÎ£å ({step1_time:.2f}Ï¥à)")
    print(f"\n{question_response.content}\n")

    # JSON ÌååÏã±
    try:
        content = question_response.content
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()

        analysis = json.loads(content)
        next_agents = analysis.get("next_agents", [])
        question_type = analysis.get("question_type", "general")
        queries = analysis.get("queries", {})

        print(f"üéØ ÌåêÎã® Í≤∞Í≥º:")
        print(f"   ÏßàÎ¨∏ Ïú†Ìòï: {question_type}")
        print(f"   Ìò∏Ï∂úÌï† ÏóêÏù¥Ï†ÑÌä∏: {', '.join(next_agents) if next_agents else 'none'}")
        if queries:
            for agent, query in queries.items():
                print(f"   ‚Ä¢ {agent}: {query}")
        print()

    except json.JSONDecodeError:
        print(f"‚ö†Ô∏è  JSON ÌååÏã± Ïã§Ìå®, Í∏∞Î≥∏ Ï≤òÎ¶¨Î°ú ÏßÑÌñâ\n")
        next_agents = ["legal_agent"]
        queries = {"legal_agent": user_query}

    # Step 2: Ï†ÑÎ¨∏ ÏóêÏù¥Ï†ÑÌä∏Îì§ ÏàúÏ∞® Ïã§Ìñâ
    if not next_agents or len(next_agents) == 0:
        # ÏùºÎ∞ò ÏßàÎ¨∏ - Agent AÍ∞Ä ÏßÅÏ†ë ÎãµÎ≥Ä ÏÉùÏÑ±
        print(f"üí¨ [Final Answer] Agent A ÏßÅÏ†ë ÎãµÎ≥Ä")
        print(f"{'‚îÄ'*70}\n")

        try:
            messages = [
                {"role": "system", "content": """ÎãπÏã†ÏùÄ ÏπúÏ†àÌïú AI Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏ÏûÖÎãàÎã§.
ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïóê ÎåÄÌï¥ Î™ÖÌôïÌïòÍ≥† ÏπúÏ†àÌïòÍ≤å ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.
Î≤ïÎ•†Ïù¥ÎÇò ÌåêÎ°Ä Í¥ÄÎ†® ÏßàÎ¨∏Ïù¥ ÏïÑÎãå ÏùºÎ∞òÏ†ÅÏù∏ ÎåÄÌôîÏóê ÏûêÏó∞Ïä§ÎüΩÍ≤å ÏùëÎãµÌïòÏÑ∏Ïöî."""},
                {"role": "user", "content": user_query}
            ]

            stream_start = time.time()
            stream_response = orchestrator.aoai_wrapper.chat_completion(messages, stream=True)

            collected_content = ""
            for chunk in stream_response:
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        print(delta.content, end="", flush=True)
                        collected_content += delta.content

            stream_time = time.time() - stream_start
            print(f"\n\n‚è±Ô∏è  ÎãµÎ≥Ä ÏÉùÏÑ± ÏãúÍ∞Ñ: {stream_time:.2f}Ï¥à")

            return collected_content

        except ContentFilterError as e:
            print(f"\nüö´ ÏΩòÌÖêÏ∏† ÌïÑÌÑ∞ÎßÅ Ï∞®Îã®: {', '.join(e.filtered_categories)}")
            return "Ï£ÑÏÜ°Ìï©ÎãàÎã§. ÎãµÎ≥ÄÏù¥ ÏΩòÌÖêÏ∏† Ï†ïÏ±ÖÏóê ÏùòÌï¥ Ï∞®Îã®ÎêòÏóàÏäµÎãàÎã§."
        except Exception as e:
            print(f"\n‚ö†Ô∏è  ÎãµÎ≥Ä ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return question_response.content

    agent_results = {}
    step_num = 2

    for agent_name in next_agents:
        if agent_name not in ["legal_agent", "precedent_agent"]:
            continue

        if agent_name == "legal_agent":
            print(f"‚öñÔ∏è  [Step {step_num}] Agent B: Î≤ïÎ•† Ï†ÑÎ¨∏Í∞Ä Ï≤òÎ¶¨")
            print(f"{'‚îÄ'*70}")
            specialist_agent = orchestrator.legal_agent
            emoji = "‚öñÔ∏è"
        else:  # precedent_agent
            print(f"üìö [Step {step_num}] Agent C: ÌåêÎ°Ä Ï†ÑÎ¨∏Í∞Ä Ï≤òÎ¶¨")
            print(f"{'‚îÄ'*70}")
            specialist_agent = orchestrator.precedent_agent
            emoji = "üìö"

        query = queries.get(agent_name, user_query)
        print(f"ÏßàÎ¨∏: {query}\n")

        step_start = time.time()

        context = {
            "original_query": user_query,
            "analysis": question_response.content,
            "structured_query": query
        }

        response = await specialist_agent.process_with_tools(query, context)
        step_time = time.time() - step_start

        if response.success:
            print(f"\n‚úÖ {emoji} Ï≤òÎ¶¨ ÏôÑÎ£å ({step_time:.2f}Ï¥à)\n")
            agent_results[agent_name] = {
                "agent": specialist_agent.name,
                "query": query,
                "response": response.content,
                "time": step_time
            }
        else:
            print(f"\n‚ùå {emoji} Ï≤òÎ¶¨ Ïã§Ìå®: {response.content}\n")
            agent_results[agent_name] = {
                "agent": specialist_agent.name,
                "query": query,
                "response": f"[ERROR] {response.content}",
                "time": step_time
            }

        step_num += 1

    # Í≤∞Í≥ºÍ∞Ä ÏóÜÏúºÎ©¥ Î∂ÑÏÑù Í≤∞Í≥ºÎßå Î∞òÌôò
    if not agent_results:
        return question_response.content

    # Step 3: Agent A - Í≤∞Í≥º ÌÜµÌï© Î∞è ÏµúÏ¢Ö ÎãµÎ≥Ä ÏÉùÏÑ±
    print(f"üîÑ [Step {step_num}] Agent A: Í≤∞Í≥º ÌÜµÌï© Î∞è ÏµúÏ¢Ö ÎãµÎ≥Ä ÏÉùÏÑ±")
    print(f"{'‚îÄ'*70}\n")

    try:
        # Ï†ÑÎ¨∏Í∞Ä ÎãµÎ≥ÄÎì§ÏùÑ Íµ¨Ï°∞Ìôî
        expert_answers = ""
        for agent_name, result in agent_results.items():
            expert_answers += f"\n\n[{result['agent']}Ïùò ÎãµÎ≥Ä]\nÏßàÎ¨∏: {result['query']}\nÎãµÎ≥Ä: {result['response']}"

        messages = [
            {"role": "system", "content": """ÎãπÏã†ÏùÄ Ïó¨Îü¨ Ï†ÑÎ¨∏Í∞ÄÏùò ÎãµÎ≥ÄÏùÑ ÌÜµÌï©ÌïòÏó¨ ÏÇ¨Ïö©ÏûêÏóêÍ≤å ÏµúÏ¢Ö ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌïòÎäî ÏΩîÎîîÎÑ§Ïù¥ÌÑ∞ÏûÖÎãàÎã§.
Í∞Å Ï†ÑÎ¨∏Í∞ÄÏùò ÎãµÎ≥ÄÏùÑ Ï¢ÖÌï©ÌïòÏó¨:
1. ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏Ïóê ÎåÄÌïú Î™ÖÌôïÌïú ÎãµÎ≥Ä
2. Î≤ïÎ•† Ï†ÑÎ¨∏Í∞ÄÏôÄ ÌåêÎ°Ä Ï†ÑÎ¨∏Í∞ÄÏùò ÎãµÎ≥ÄÏùÑ ÎÖºÎ¶¨Ï†ÅÏúºÎ°ú Ïó∞Í≤∞
3. Ïù¥Ìï¥ÌïòÍ∏∞ ÏâΩÍ≥† Ï≤¥Í≥ÑÏ†ÅÏù∏ ÏÑ§Î™Ö

Îã§Ïùå Íµ¨Ï°∞Î°ú ÎãµÎ≥ÄÌïòÏÑ∏Ïöî:
- Í∞úÏöî
- Î≤ïÎ•†Ï†Å ÏÑ§Î™Ö (Î≤ïÎ•† Ï†ÑÎ¨∏Í∞Ä ÎãµÎ≥Ä Í∏∞Î∞ò)
- Ïã§Ï†ú ÏÇ¨Î°Ä (ÌåêÎ°Ä Ï†ÑÎ¨∏Í∞Ä ÎãµÎ≥Ä Í∏∞Î∞ò)
- Í≤∞Î°† Î∞è ÏãúÏÇ¨Ï†ê"""},
            {"role": "user", "content": f"""ÏõêÎ≥∏ ÏßàÎ¨∏: {user_query}

ÏßàÎ¨∏ Î∂ÑÏÑù:
{question_response.content}

Ï†ÑÎ¨∏Í∞Ä ÎãµÎ≥ÄÎì§:
{expert_answers}

ÏúÑ ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú ÏÇ¨Ïö©ÏûêÏóêÍ≤å ÏµúÏ¢Ö ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî."""}
        ]

        stream_start = time.time()
        stream_response = orchestrator.aoai_wrapper.chat_completion(messages, stream=True)

        collected_content = ""
        for chunk in stream_response:
            if chunk.choices and len(chunk.choices) > 0:
                delta = chunk.choices[0].delta
                if hasattr(delta, 'content') and delta.content:
                    print(delta.content, end="", flush=True)
                    collected_content += delta.content

        stream_time = time.time() - stream_start
        print(f"\n\n‚è±Ô∏è  ÌÜµÌï© ÎãµÎ≥Ä ÏÉùÏÑ± ÏãúÍ∞Ñ: {stream_time:.2f}Ï¥à")

        return collected_content

    except ContentFilterError as e:
        print(f"\nüö´ ÏΩòÌÖêÏ∏† ÌïÑÌÑ∞ÎßÅ Ï∞®Îã®: {', '.join(e.filtered_categories)}")
        # ÏΩòÌÖêÏ∏† ÌïÑÌÑ∞ÎßÅ Ïãú ÏõêÎ≥∏ ÎãµÎ≥ÄÎì§ Î∞òÌôò
        return "\n\n".join([f"[{r['agent']}]\n{r['response']}" for r in agent_results.values()])
    except Exception as e:
        print(f"\n‚ö†Ô∏è  ÌÜµÌï© Ïã§Ìå®, Í∞úÎ≥Ñ ÎãµÎ≥Ä Î∞òÌôò: {e}")
        # ÏóêÎü¨ Ïãú ÏõêÎ≥∏ ÎãµÎ≥ÄÎì§ Î∞òÌôò
        return "\n\n".join([f"[{r['agent']}]\n{r['response']}" for r in agent_results.values()])


async def main():
    print("="*70)
    print("ü§ñ Multi-Agent System: Question ‚Üí Legal/Precedent Expert ‚Üí Answer")
    print("="*70)

    orchestrator = None
    try:
        orchestrator = await initialize_multi_agent()
        print("\n‚úÖ Multi-Agent System is ready!")
        print("Type 'quit' or 'exit' to stop.\n")

        while True:
            q = input("\nüßë You> ").strip()
            if q.lower() in {"quit", "exit", "q"}:
                break
            if not q:
                continue

            try:
                conversation_start = time.time()
                ans = await run_multi_agent_conversation(orchestrator, q)
                total_time = time.time() - conversation_start
                print(f"\n‚è±Ô∏è  Ï¥ù ÏÜåÏöî ÏãúÍ∞Ñ: {total_time:.2f}Ï¥à")
            except (ContentFilterError, BadRequestError):
                pass
            except Exception as e:
                print(f"\n‚ùå [Error] {e}")
                import traceback
                traceback.print_exc()

    except KeyboardInterrupt:
        print("\n\nüëã Interrupted by user.")
    except Exception as e:
        print(f"\n‚ùå [Fatal Error] {e}")
        import traceback
        traceback.print_exc()
    finally:
        if orchestrator:
            print("\nüîå Closing all MCP server connections...")
            try:
                await orchestrator.close_all_servers()
                print("‚úì All connections closed.")
            except asyncio.CancelledError:
                print("‚ö†Ô∏è  Connection cleanup was cancelled")
            except Exception as e:
                print(f"‚ö†Ô∏è  Error during cleanup: {e}")


if __name__ == "__main__":
    asyncio.run(main())

