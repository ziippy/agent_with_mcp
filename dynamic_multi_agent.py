import os
import json
import asyncio
import time
from typing import Any, Dict, List, Optional
from dataclasses import dataclass

from dotenv import load_dotenv
from openai import AzureOpenAI, BadRequestError

from google.adk.tools import BaseTool
from google.adk.tools.mcp_tool.mcp_toolset import McpToolset
from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPConnectionParams

load_dotenv()


class ContentFilterError(Exception):
    """Azure OpenAI ì½˜í…ì¸  í•„í„°ë§ ì—ëŸ¬"""
    def __init__(self, filtered_categories: List[str], original_error: Exception):
        self.filtered_categories = filtered_categories
        self.original_error = original_error
        super().__init__(f"Content filtered: {', '.join(filtered_categories)}")


class AzureOpenAIWrapper:
    """Azure OpenAI ë˜í¼"""

    def __init__(self, api_key: str, api_version: str, azure_endpoint: str, deployment: str):
        try:
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint,
            )
            self.deployment = deployment
        except Exception as e:
            print("[AOAI] init failed ->", e)

    def chat_completion(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]] = None, stream: bool = False):
        """Azure OpenAI Chat Completion í˜¸ì¶œ"""
        try:
            kwargs = {
                "model": self.deployment,
                "messages": messages,
                "temperature": 0.2,
                "stream": stream,
            }

            if tools:
                kwargs["tools"] = tools
                kwargs["tool_choice"] = "auto"

            return self.client.chat.completions.create(**kwargs)
        except BadRequestError as e:
            error_str = str(e)

            if 'content_filter' in error_str or 'content management policy' in error_str.lower():
                error_body = getattr(e, 'body', None)
                filtered_categories = []

                if error_body and isinstance(error_body, dict):
                    error_info = error_body.get('error', {})
                    inner_error = error_info.get('innererror', {})
                    filter_result = inner_error.get('content_filter_result', {})

                    for category, details in filter_result.items():
                        if isinstance(details, dict) and details.get('filtered'):
                            severity = details.get('severity', 'unknown')
                            filtered_categories.append(f"{category}={severity}")

                if not filtered_categories:
                    filtered_categories = ['content_filter']

                raise ContentFilterError(
                    filtered_categories=filtered_categories,
                    original_error=e
                )

            raise


@dataclass
class MCPServerConnection:
    """ë‹¨ì¼ MCP ì„œë²„ ì—°ê²°"""
    name: str
    toolset: McpToolset


@dataclass
class AgentResponse:
    """ì—ì´ì „íŠ¸ ì‘ë‹µ"""
    content: str
    metadata: Dict[str, Any]
    success: bool
    agent_name: str


class SpecializedAgent:
    """íŠ¹í™”ëœ ì—ì´ì „íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self, name: str, role: str, system_prompt: str, aoai_wrapper: AzureOpenAIWrapper):
        self.name = name
        self.role = role
        self.system_prompt = system_prompt
        self.aoai_wrapper = aoai_wrapper

    async def process(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """ì—ì´ì „íŠ¸ ì²˜ë¦¬"""
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_input}
        ]

        if context:
            context_str = f"\n\n[Context from previous agents]\n{json.dumps(context, indent=2, ensure_ascii=False)}"
            messages[-1]["content"] += context_str

        try:
            response = self.aoai_wrapper.chat_completion(messages, stream=False)
            content = response.choices[0].message.content or ""

            return AgentResponse(
                content=content,
                metadata={"tokens": response.usage.total_tokens if hasattr(response, 'usage') else 0},
                success=True,
                agent_name=self.name
            )
        except ContentFilterError as e:
            return AgentResponse(
                content=f"ì½˜í…ì¸  í•„í„°ë§ ì°¨ë‹¨: {', '.join(e.filtered_categories)}",
                metadata={"error": str(e)},
                success=False,
                agent_name=self.name
            )
        except Exception as e:
            return AgentResponse(
                content=f"ì—ëŸ¬ ë°œìƒ: {str(e)}",
                metadata={"error": str(e)},
                success=False,
                agent_name=self.name
            )


class QuestionUnderstandingAgent(SpecializedAgent):
    """Agent A: ì§ˆë¬¸ ì´í•´ ë° ë¼ìš°íŒ… ë‹´ë‹¹"""

    def __init__(self, aoai_wrapper: AzureOpenAIWrapper, available_agents: List[str], agent_tools_info: Dict[str, List[str]]):
        """
        Args:
            aoai_wrapper: Azure OpenAI ë˜í¼
            available_agents: ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡ (ì˜ˆ: ["mcp1", "mcp2", "mcp3"])
            agent_tools_info: ê° ì—ì´ì „íŠ¸ì˜ ë„êµ¬ ì •ë³´ {"mcp1": ["tool1", "tool2"], ...}
        """
        agents_str = ", ".join(available_agents)

        # ê° ì—ì´ì „íŠ¸ì˜ ë„êµ¬ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·
        tools_info_str = ""
        for agent, tools in agent_tools_info.items():
            tools_list = ", ".join(tools[:5])  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            if len(tools) > 5:
                tools_list += f"... (ì´ {len(tools)}ê°œ)"
            tools_info_str += f"\n  - {agent}: {tools_list}"

        system_prompt = f"""ë‹¹ì‹ ì€ ì§ˆë¬¸ ë¶„ì„ ë° ë¼ìš°íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì „ë¬¸ ì—ì´ì „íŠ¸ì—ê²Œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ë° ë„êµ¬: {tools_info_str}

**ì¤‘ìš”**: ê° ì—ì´ì „íŠ¸ê°€ ê°€ì§„ ë„êµ¬ë¥¼ ë³´ê³  ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì¶”ë¡ í•˜ì„¸ìš”.
ì˜ˆ: precedent-search, case-search â†’ íŒë¡€/ì‚¬ë¡€ ê²€ìƒ‰
    law-search, statute-search â†’ ë²•ë¥ /ì¡°ë¬¸ ê²€ìƒ‰
    web-search â†’ ì›¹ ê²€ìƒ‰

**ì¤‘ìš” ì›ì¹™:**
1. ì§ˆë¬¸ì´ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ í•„ìš”ë¡œ í•˜ë©´ **ì‹¤í–‰ ìˆœì„œ**ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ê²°ì •
2. ë‚˜ì¤‘ ì—ì´ì „íŠ¸ê°€ ì´ì „ ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ í™œìš©í•  ìˆ˜ ìˆìœ¼ë©´ ì˜ì¡´ì„± ëª…ì‹œ
3. ì¼ë°˜ì ì¸ ëŒ€í™”ëŠ” ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ì§€ ì•ŠìŒ (execution_order: [])

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:
{{
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
  "question_type": "single|multiple|general",
  "execution_order": ["{available_agents[0] if available_agents else 'agent_name'}"] or ["{available_agents[1] if len(available_agents) > 1 else 'agent_name'}"] or [],
  "queries": {{
    "agent_name": "í•´ë‹¹ ì—ì´ì „íŠ¸ì—ê²Œ í•  êµ¬ì²´ì ì¸ ì§ˆë¬¸"
  }},
  "dependencies": {{
    "agent_name": "ì´ì „ ì—ì´ì „íŠ¸ ê²°ê³¼ í™œìš© ë°©ë²• (ì„ íƒì‚¬í•­)"
  }},
  "analysis": "ì§ˆë¬¸ ë¶„ì„ ë° ì‹¤í–‰ ìˆœì„œ ì´ìœ "
}}

ì˜ˆì‹œ (available_agents: ["mcp1", "mcp2"]):
- ë‹¨ì¼ ì—ì´ì „íŠ¸: execution_order: ["mcp1"]
- ë³µí•© (ìˆœì°¨): execution_order: ["mcp1", "mcp2"]
- ë³µí•© (ì—­ìˆœ): execution_order: ["mcp2", "mcp1"] 
- ì¼ë°˜ ëŒ€í™”: execution_order: []"""
        super().__init__(
            name="QuestionUnderstandingAgent",
            role="ì§ˆë¬¸ ì´í•´ ë° ë¼ìš°íŒ…",
            system_prompt=system_prompt,
            aoai_wrapper=aoai_wrapper
        )


class ToolBasedAgent(SpecializedAgent):
    """ë„êµ¬ ê¸°ë°˜ ì „ë¬¸ ì—ì´ì „íŠ¸ (ë²”ìš©)"""

    def __init__(self, name: str, role: str, aoai_wrapper: AzureOpenAIWrapper, tools: List[BaseTool]):
        system_prompt = f"""ë‹¹ì‹ ì€ {role} ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
í•„ìš”ì‹œ ì œê³µëœ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {len(tools)}ê°œ"""
        super().__init__(
            name=name,
            role=role,
            system_prompt=system_prompt,
            aoai_wrapper=aoai_wrapper
        )
        self.tools = tools

    async def process_with_tools(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬"""
        tools_for_openai = []
        for tool in self.tools:
            tool_name = getattr(tool, 'name', type(tool).__name__)
            tool_description = getattr(tool, 'description', '')
            tool_input_schema = getattr(tool, 'input_schema', None) or {"type": "object", "properties": {}}
            tools_for_openai.append({
                "type": "function",
                "function": {
                    "name": tool_name,
                    "description": tool_description or "",
                    "parameters": tool_input_schema,
                },
            })

        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_input}
        ]

        if context:
            context_str = f"\n\n[Context]\n{json.dumps(context, indent=2, ensure_ascii=False)}"
            messages[-1]["content"] += context_str

        max_iterations = 5
        for iteration in range(max_iterations):
            try:
                response = self.aoai_wrapper.chat_completion(messages, tools=tools_for_openai, stream=False)
                choice = response.choices[0].message

                if not getattr(choice, "tool_calls", None):
                    return AgentResponse(
                        content=choice.content or "",
                        metadata={"iterations": iteration + 1},
                        success=True,
                        agent_name=self.name
                    )

                print(f"  ğŸ”§ [{self.name}] Tool calls: {len(choice.tool_calls)}", flush=True)
                tool_results = []

                for tc in choice.tool_calls:
                    tool_name = tc.function.name
                    args = json.loads(tc.function.arguments) if tc.function.arguments else {}

                    for tool in self.tools:
                        current_tool_name = getattr(tool, 'name', type(tool).__name__)
                        if current_tool_name == tool_name:
                            try:
                                from google.adk.models import LlmRequest
                                class DummyToolContext:
                                    def __init__(self):
                                        self.llm_request = LlmRequest(contents=[])

                                tool_context = DummyToolContext()
                                result = await tool.run_async(args=args, tool_context=tool_context)
                                tool_results.append({
                                    "tool_call_id": tc.id,
                                    "content": str(result),
                                })
                                print(f"    âœ… Tool {tool_name} executed", flush=True)
                                break
                            except Exception as e:
                                tool_results.append({
                                    "tool_call_id": tc.id,
                                    "content": f"Error: {str(e)}",
                                })
                                break

                messages.append({
                    "role": "assistant",
                    "content": choice.content or "",
                    "tool_calls": [tc.model_dump() for tc in choice.tool_calls],
                })
                for tr in tool_results:
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tr["tool_call_id"],
                        "content": tr["content"],
                    })

            except Exception as e:
                return AgentResponse(
                    content=f"ì—ëŸ¬ ë°œìƒ: {str(e)}",
                    metadata={"error": str(e), "iteration": iteration},
                    success=False,
                    agent_name=self.name
                )

        return AgentResponse(
            content="ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬",
            metadata={"iterations": max_iterations},
            success=False,
            agent_name=self.name
        )


class MultiAgentOrchestrator:
    """ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - ë™ì  ì—ì´ì „íŠ¸ ê´€ë¦¬"""

    def __init__(self):
        self.servers: Dict[str, MCPServerConnection] = {}
        self.all_tools: List[BaseTool] = []
        self.aoai_wrapper: Optional[AzureOpenAIWrapper] = None

        self.question_agent: Optional[QuestionUnderstandingAgent] = None
        self.specialist_agents: Dict[str, ToolBasedAgent] = {}  # MCP ì„œë²„ë³„ ì—ì´ì „íŠ¸

    def _normalize_url(self, url: str) -> str:
        """URL ì •ê·œí™”"""
        return url if url.endswith("/") else url + "/"

    def _prefix_tool(self, tool: BaseTool, prefix: str) -> BaseTool:
        """ë„êµ¬ ì´ë¦„ì— prefix ì¶”ê°€"""
        class PrefixedTool(tool.__class__):
            @property
            def name(self):
                original = getattr(super(), "name", getattr(tool, "name", type(tool).__name__))
                return f"{prefix}__{original}"

        wrapped = PrefixedTool.__new__(PrefixedTool)
        wrapped.__dict__ = tool.__dict__.copy()
        return wrapped

    async def connect_mcp_server(self, server_name: str, base_url: str, auth_bearer: str = "") -> MCPServerConnection:
        """MCP ì„œë²„ ì—°ê²° ë° ì—ì´ì „íŠ¸ ìë™ ìƒì„±"""
        base_url = self._normalize_url(base_url)
        headers = {}
        if auth_bearer:
            headers["Authorization"] = f"Bearer {auth_bearer}"
        try:
            conn_params = StreamableHTTPConnectionParams(
                url=base_url,
                headers=headers if headers else None,
                timeout=10.0,
                sse_read_timeout=300.0,
            )
            toolset = McpToolset(connection_params=conn_params)
            tools = await toolset.get_tools()
            connection = MCPServerConnection(
                name=server_name,
                toolset=toolset
            )
            self.servers[server_name] = connection

            # ë„êµ¬ì— prefix ì¶”ê°€
            prefixed_tools = []
            for tool in tools:
                prefixed_tool = self._prefix_tool(tool, server_name)
                prefixed_tools.append(prefixed_tool)
                self.all_tools.append(prefixed_tool)

            # ì—ì´ì „íŠ¸ ìë™ ìƒì„± (ì´ˆê¸°í™” í›„)
            # initialize_agentsì—ì„œ ì²˜ë¦¬

            return connection
        except Exception as e:
            error_msg = str(e)
            print(f"\n[Error] Failed to connect to {server_name}: {error_msg}")
            print(f" URL: {base_url}")
            if server_name in self.servers:
                del self.servers[server_name]
            raise RuntimeError(f"Failed to connect to MCP server {server_name} at {base_url}: {error_msg}") from e

    def initialize_agents(self):
        """ê°œë³„ íŠ¹í™” ì—ì´ì „íŠ¸ë“¤ì„ ë™ì ìœ¼ë¡œ ì´ˆê¸°í™”"""
        self.aoai_wrapper = AzureOpenAIWrapper(
            api_key=os.environ["AZURE_OPENAI_API_KEY"],
            api_version=os.environ["AZURE_OPENAI_API_VERSION"],
            azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
            deployment=os.environ["AZURE_OPENAI_DEPLOYMENT"],
        )

        # ê° ì„œë²„ë³„ ë„êµ¬ ì •ë³´ ìˆ˜ì§‘
        agent_tools_info = {}
        for server_name in self.servers.keys():
            server_tools = [tool for tool in self.all_tools if getattr(tool, 'name', '').startswith(f'{server_name}__')]
            tool_names = [getattr(tool, 'name', '').replace(f'{server_name}__', '') for tool in server_tools]
            agent_tools_info[server_name] = tool_names

        # Agent A ì´ˆê¸°í™” (ë¼ìš°íŒ… ì—ì´ì „íŠ¸) - ë„êµ¬ ì •ë³´ í¬í•¨
        available_agents = list(self.servers.keys())
        self.question_agent = QuestionUnderstandingAgent(self.aoai_wrapper, available_agents, agent_tools_info)

        # ê° MCP ì„œë²„ë³„ë¡œ ì—ì´ì „íŠ¸ ìë™ ìƒì„±
        print(f"\nâœ… ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ:")
        print(f"   â€¢ {self.question_agent.name}: {self.question_agent.role}")

        for server_name in self.servers.keys():
            # í•´ë‹¹ ì„œë²„ì˜ ë„êµ¬ë§Œ í•„í„°ë§
            server_tools = [tool for tool in self.all_tools if getattr(tool, 'name', '').startswith(f'{server_name}__')]

            # ì—ì´ì „íŠ¸ ìƒì„±
            agent = ToolBasedAgent(
                name=f"{server_name.upper()}Agent",
                role=f"{server_name} ì „ë¬¸ ì„œë¹„ìŠ¤",
                aoai_wrapper=self.aoai_wrapper,
                tools=server_tools
            )
            self.specialist_agents[server_name] = agent
            print(f"   â€¢ {agent.name}: {agent.role} (ë„êµ¬ {len(server_tools)}ê°œ)")
            # ë„êµ¬ ëª©ë¡ ì¶œë ¥
            for tool in server_tools[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                tool_name = getattr(tool, 'name', '')
                print(f"      - {tool_name}")
            if len(server_tools) > 3:
                print(f"      ... and {len(server_tools) - 3} more tools")

    async def close_all_servers(self):
        """ëª¨ë“  MCP ì„œë²„ ì—°ê²° ì¢…ë£Œ"""
        for server_name, server in list(self.servers.items()):
            try:
                if server.toolset:
                    await asyncio.wait_for(server.toolset.close(), timeout=5.0)
                    print(f"âœ“ Closed {server_name}")
            except asyncio.TimeoutError:
                print(f"âš ï¸  Timeout closing server {server_name}")
            except asyncio.CancelledError:
                print(f"âš ï¸  Cancelled while closing server {server_name}")
            except Exception as e:
                print(f"âš ï¸  Error closing server {server_name}: {e}")
        self.servers.clear()
        self.all_tools.clear()
        self.specialist_agents.clear()


async def initialize_multi_agent() -> MultiAgentOrchestrator:
    """ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - ë™ì  MCP ì„œë²„ ì—°ê²°"""
    orchestrator = MultiAgentOrchestrator()
    connected_servers = []

    try:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ MCP ì„œë²„ ëª©ë¡ ë™ì  ë¡œë“œ
        server_index = 1
        while True:
            url_key = f"MCP_SERVER_{server_index}_URL"
            bearer_key = f"MCP_SERVER_{server_index}_AUTH_BEARER"
            name_key = f"MCP_SERVER_{server_index}_NAME"

            server_url = os.environ.get(url_key, "")
            if not server_url:
                break

            server_bearer = os.environ.get(bearer_key, "")
            server_name = os.environ.get(name_key, f"mcp{server_index}")

            print(f"Connecting to MCP Server '{server_name}': {server_url}")
            try:
                await orchestrator.connect_mcp_server(server_name, server_url, server_bearer)
                print(f"âœ“ Connected to {server_name}")
                connected_servers.append(server_name)
            except Exception as e:
                print(f"âœ— Failed to connect to {server_name}: {e}")

            server_index += 1

        if not connected_servers:
            raise RuntimeError("No MCP servers connected. Check your .env configuration.")

        print(f"\nâœ… Connected to {len(connected_servers)} MCP server(s): {', '.join(connected_servers)}")
        print("\nInitializing Multi-Agent System...")
        orchestrator.initialize_agents()
        print(f"âœ“ Multi-Agent System initialized with {len(orchestrator.all_tools)} total tools\n")

        return orchestrator

    except Exception as e:
        raise RuntimeError(f"Failed to initialize multi-agent system: {e}") from e


async def run_multi_agent_conversation(orchestrator: MultiAgentOrchestrator, user_query: str) -> str:
    """ë©€í‹° ì—ì´ì „íŠ¸ ëŒ€í™” ì‹¤í–‰"""

    print(f"\n{'='*70}")
    print(f"ğŸ¤– Multi-Agent Processing Pipeline")
    print(f"{'='*70}\n")

    # Step 1: Agent A - ì§ˆë¬¸ ë¶„ì„
    print(f"ğŸ“‹ [Step 1] Agent A: ì§ˆë¬¸ ë¶„ì„ ë° ë¼ìš°íŒ…")
    print(f"{'â”€'*70}")

    step1_start = time.time()
    question_response = await orchestrator.question_agent.process(user_query)
    step1_time = time.time() - step1_start

    if not question_response.success:
        print(f"âŒ ì§ˆë¬¸ ë¶„ì„ ì‹¤íŒ¨: {question_response.content}")
        return question_response.content

    print(f"âœ… ë¶„ì„ ì™„ë£Œ ({step1_time:.2f}ì´ˆ)")
    print(f"\n{question_response.content}\n")

    # JSON íŒŒì‹±
    try:
        content = question_response.content
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()

        analysis = json.loads(content)
        execution_order = analysis.get("execution_order", [])
        question_type = analysis.get("question_type", "general")
        queries = analysis.get("queries", {})
        dependencies = analysis.get("dependencies", {})

        print(f"ğŸ¯ íŒë‹¨ ê²°ê³¼:")
        print(f"   ì§ˆë¬¸ ìœ í˜•: {question_type}")
        print(f"   ì‹¤í–‰ ìˆœì„œ: {' â†’ '.join(execution_order) if execution_order else 'none'}")
        if queries:
            for i, agent in enumerate(execution_order, 1):
                if agent in queries:
                    print(f"   {i}. {agent}: {queries[agent]}")
                    if agent in dependencies:
                        print(f"      â””â”€ ì˜ì¡´ì„±: {dependencies[agent]}")
        print()

    except json.JSONDecodeError:
        print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ ì²˜ë¦¬ë¡œ ì§„í–‰\n")
        execution_order = []
        queries = {}
        dependencies = {}

    # Step 2: ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ ìˆœì°¨ ì‹¤í–‰
    if not execution_order:
        # ì¼ë°˜ ì§ˆë¬¸ - Agent Aê°€ ì§ì ‘ ë‹µë³€
        print(f"ğŸ’¬ [Final Answer] Agent A ì§ì ‘ ë‹µë³€")
        print(f"{'â”€'*70}\n")

        try:
            messages = [
                {"role": "system", "content": """ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""},
                {"role": "user", "content": user_query}
            ]

            stream_start = time.time()
            stream_response = orchestrator.aoai_wrapper.chat_completion(messages, stream=True)

            collected_content = ""
            for chunk in stream_response:
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        print(delta.content, end="", flush=True)
                        collected_content += delta.content

            stream_time = time.time() - stream_start
            print(f"\n\nâ±ï¸  ë‹µë³€ ìƒì„± ì‹œê°„: {stream_time:.2f}ì´ˆ")

            return collected_content

        except Exception as e:
            print(f"\nâš ï¸  ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return question_response.content

    agent_results = {}
    previous_results = []
    step_num = 2

    # execution_order ìˆœì„œëŒ€ë¡œ ì—ì´ì „íŠ¸ ì‹¤í–‰
    for agent_name in execution_order:
        if agent_name not in orchestrator.specialist_agents:
            print(f"âš ï¸  ì—ì´ì „íŠ¸ '{agent_name}' not found, skipping...")
            continue

        specialist_agent = orchestrator.specialist_agents[agent_name]

        print(f"ğŸ”§ [Step {step_num}] {specialist_agent.name} ì²˜ë¦¬")
        print(f"{'â”€'*70}")

        query = queries.get(agent_name, user_query)
        dependency = dependencies.get(agent_name, "")

        print(f"ì§ˆë¬¸: {query}")
        if dependency and previous_results:
            print(f"ì˜ì¡´ì„±: {dependency}")
        print()

        step_start = time.time()

        context = {
            "original_query": user_query,
            "analysis": question_response.content,
            "structured_query": query,
        }

        if previous_results:
            context["previous_agent_results"] = previous_results
            if dependency:
                context["dependency_instruction"] = dependency

        response = await specialist_agent.process_with_tools(query, context)
        step_time = time.time() - step_start

        if response.success:
            print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ ({step_time:.2f}ì´ˆ)\n")
            result_info = {
                "agent": specialist_agent.name,
                "agent_name": agent_name,
                "query": query,
                "response": response.content,
                "time": step_time
            }
            agent_results[agent_name] = result_info
            previous_results.append(result_info)
        else:
            print(f"\nâŒ ì²˜ë¦¬ ì‹¤íŒ¨: {response.content}\n")

        step_num += 1

    if not agent_results:
        return question_response.content

    # Step 3: Agent A - ê²°ê³¼ í†µí•©
    print(f"ğŸ”„ [Step {step_num}] Agent A: ê²°ê³¼ í†µí•© ë° ìµœì¢… ë‹µë³€ ìƒì„±")
    print(f"{'â”€'*70}\n")

    try:
        expert_answers = ""
        for i, agent_name in enumerate(execution_order, 1):
            if agent_name in agent_results:
                result = agent_results[agent_name]
                expert_answers += f"\n\n[{i}ë‹¨ê³„: {result['agent']}ì˜ ë‹µë³€]\nì§ˆë¬¸: {result['query']}\në‹µë³€: {result['response']}"

        messages = [
            {"role": "system", "content": """ë‹¹ì‹ ì€ ì—¬ëŸ¬ ì „ë¬¸ê°€ì˜ ë‹µë³€ì„ í†µí•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ëŠ” ì½”ë””ë„¤ì´í„°ì…ë‹ˆë‹¤.
ê° ì „ë¬¸ê°€ì˜ ë‹µë³€ì„ ì‹¤í–‰ ìˆœì„œëŒ€ë¡œ ì¢…í•©í•˜ì—¬ ëª…í™•í•˜ê³  ì²´ê³„ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."""},
            {"role": "user", "content": f"""ì›ë³¸ ì§ˆë¬¸: {user_query}

ì „ë¬¸ê°€ ë‹µë³€ë“¤ (ì‹¤í–‰ ìˆœì„œ):
{expert_answers}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""}
        ]

        stream_start = time.time()
        stream_response = orchestrator.aoai_wrapper.chat_completion(messages, stream=True)

        collected_content = ""
        for chunk in stream_response:
            if chunk.choices and len(chunk.choices) > 0:
                delta = chunk.choices[0].delta
                if hasattr(delta, 'content') and delta.content:
                    print(delta.content, end="", flush=True)
                    collected_content += delta.content

        stream_time = time.time() - stream_start
        print(f"\n\nâ±ï¸  í†µí•© ë‹µë³€ ìƒì„± ì‹œê°„: {stream_time:.2f}ì´ˆ")

        return collected_content

    except Exception as e:
        print(f"\nâš ï¸  í†µí•© ì‹¤íŒ¨: {e}")
        return "\n\n".join([f"[{r['agent']}]\n{r['response']}" for r in agent_results.values()])


async def main():
    print("="*70)
    print("ğŸ¤– Dynamic Multi-Agent System")
    print("="*70)

    orchestrator = None
    try:
        orchestrator = await initialize_multi_agent()
        print("\nâœ… Multi-Agent System is ready!")
        print("Type 'quit' or 'exit' to stop.\n")

        while True:
            q = input("\nğŸ§‘ You> ").strip()
            if q.lower() in {"quit", "exit", "q"}:
                break
            if not q:
                continue

            try:
                conversation_start = time.time()
                ans = await run_multi_agent_conversation(orchestrator, q)
                total_time = time.time() - conversation_start
                print(f"\nâ±ï¸  ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
            except Exception as e:
                print(f"\nâŒ [Error] {e}")
                import traceback
                traceback.print_exc()

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Interrupted by user.")
    except Exception as e:
        print(f"\nâŒ [Fatal Error] {e}")
        import traceback
        traceback.print_exc()
    finally:
        if orchestrator:
            print("\nğŸ”Œ Closing all MCP server connections...")
            try:
                await orchestrator.close_all_servers()
                print("âœ“ All connections closed.")
            except Exception as e:
                print(f"âš ï¸  Error during cleanup: {e}")


if __name__ == "__main__":
    asyncio.run(main())

