import os
import json
import asyncio
import time
from typing import Any, Dict, List, Optional
from dataclasses import dataclass

from dotenv import load_dotenv
from openai import AzureOpenAI, BadRequestError

from google.adk.tools import BaseTool
from google.adk.tools.mcp_tool.mcp_toolset import McpToolset
from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPConnectionParams

load_dotenv()


class ContentFilterError(Exception):
    """Azure OpenAI ì½˜í…ì¸  í•„í„°ë§ ì—ëŸ¬"""
    def __init__(self, filtered_categories: List[str], original_error: Exception):
        self.filtered_categories = filtered_categories
        self.original_error = original_error
        super().__init__(f"Content filtered: {', '.join(filtered_categories)}")


class AzureOpenAIWrapper:
    """Azure OpenAI ë˜í¼"""

    def __init__(self, api_key: str, api_version: str, azure_endpoint: str, deployment: str):
        try:
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint,
            )
            self.deployment = deployment
        except Exception as e:
            print("[AOAI] init failed ->", e)

    def chat_completion(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]] = None, stream: bool = False):
        """Azure OpenAI Chat Completion í˜¸ì¶œ"""
        try:
            kwargs = {
                "model": self.deployment,
                "messages": messages,
                "temperature": 0.2,
                "stream": stream,
            }

            if tools:
                kwargs["tools"] = tools
                kwargs["tool_choice"] = "auto"

            return self.client.chat.completions.create(**kwargs)
        except BadRequestError as e:
            error_str = str(e)

            if 'content_filter' in error_str or 'content management policy' in error_str.lower():
                error_body = getattr(e, 'body', None)
                filtered_categories = []

                if error_body and isinstance(error_body, dict):
                    error_info = error_body.get('error', {})
                    inner_error = error_info.get('innererror', {})
                    filter_result = inner_error.get('content_filter_result', {})

                    for category, details in filter_result.items():
                        if isinstance(details, dict) and details.get('filtered'):
                            severity = details.get('severity', 'unknown')
                            filtered_categories.append(f"{category}={severity}")

                if not filtered_categories:
                    filtered_categories = ['content_filter']

                raise ContentFilterError(
                    filtered_categories=filtered_categories,
                    original_error=e
                )

            raise


@dataclass
class MCPServerConnection:
    """ë‹¨ì¼ MCP ì„œë²„ ì—°ê²°"""
    name: str
    toolset: McpToolset


@dataclass
class AgentResponse:
    """ì—ì´ì „íŠ¸ ì‘ë‹µ"""
    content: str
    metadata: Dict[str, Any]
    success: bool
    agent_name: str


class SpecializedAgent:
    """íŠ¹í™”ëœ ì—ì´ì „íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self, name: str, role: str, system_prompt: str, aoai_wrapper: AzureOpenAIWrapper):
        self.name = name
        self.role = role
        self.system_prompt = system_prompt
        self.aoai_wrapper = aoai_wrapper

    async def process(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """ì—ì´ì „íŠ¸ ì²˜ë¦¬"""
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_input}
        ]

        if context:
            context_str = f"\n\n[Context from previous agents]\n{json.dumps(context, indent=2, ensure_ascii=False)}"
            messages[-1]["content"] += context_str

        try:
            response = self.aoai_wrapper.chat_completion(messages, stream=False)
            content = response.choices[0].message.content or ""

            return AgentResponse(
                content=content,
                metadata={"tokens": response.usage.total_tokens if hasattr(response, 'usage') else 0},
                success=True,
                agent_name=self.name
            )
        except ContentFilterError as e:
            return AgentResponse(
                content=f"ì½˜í…ì¸  í•„í„°ë§ ì°¨ë‹¨: {', '.join(e.filtered_categories)}",
                metadata={"error": str(e)},
                success=False,
                agent_name=self.name
            )
        except Exception as e:
            return AgentResponse(
                content=f"ì—ëŸ¬ ë°œìƒ: {str(e)}",
                metadata={"error": str(e)},
                success=False,
                agent_name=self.name
            )


class QuestionUnderstandingAgent(SpecializedAgent):
    """Agent A: ì§ˆë¬¸ ì´í•´ ë° ë¼ìš°íŒ… ë‹´ë‹¹"""

    def __init__(self, aoai_wrapper: AzureOpenAIWrapper, available_agents: List[str], agent_tools_info: Dict[str, List[str]]):
        """
        Args:
            aoai_wrapper: Azure OpenAI ë˜í¼
            available_agents: ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡ (ì˜ˆ: ["mcp1", "mcp2", "mcp3"])
            agent_tools_info: ê° ì—ì´ì „íŠ¸ì˜ ë„êµ¬ ì •ë³´ {"mcp1": ["tool1", "tool2"], ...}
        """
        agents_str = ", ".join(available_agents)

        # ê° ì—ì´ì „íŠ¸ì˜ ë„êµ¬ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·
        tools_info_str = ""
        for agent, tools in agent_tools_info.items():
            tools_list = ", ".join(tools[:5])  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            if len(tools) > 5:
                tools_list += f"... (ì´ {len(tools)}ê°œ)"
            tools_info_str += f"\n  - {agent}: {tools_list}"

        system_prompt = f"""ë‹¹ì‹ ì€ ì§ˆë¬¸ ë¶„ì„ ë° ë¼ìš°íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì „ë¬¸ ì—ì´ì „íŠ¸ì—ê²Œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.

**ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡:**
{agents_str}

**ê° ì—ì´ì „íŠ¸ê°€ ì œê³µí•˜ëŠ” ë„êµ¬:**{tools_info_str}

**âš ï¸ ë§¤ìš° ì¤‘ìš” - execution_order ì‘ì„± ê·œì¹™:**
1. execution_orderì—ëŠ” **ë°˜ë“œì‹œ ì—ì´ì „íŠ¸ ì´ë¦„ë§Œ** ì‚¬ìš©í•˜ì„¸ìš”
2. ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ì´ë¦„: {agents_str}
3. ë„êµ¬ ì´ë¦„ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”

**ì—ì´ì „íŠ¸ ì—­í•  ì¶”ë¡  (ë„êµ¬ë¥¼ ë³´ê³  íŒë‹¨):**
ê° ì—ì´ì „íŠ¸ê°€ ì œê³µí•˜ëŠ” ë„êµ¬ë¥¼ ë³´ê³  ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì¶”ë¡ í•œ í›„, **ì—ì´ì „íŠ¸ ì´ë¦„**ì„ ì‚¬ìš©í•˜ì„¸ìš”.

**ì˜ëª»ëœ ì˜ˆì‹œ (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€):**
âŒ execution_order: [["law-search", "precedent-search"]]  <- ë„êµ¬ ì´ë¦„ ì‚¬ìš©
âŒ execution_order: [["web-search"]]  <- ë„êµ¬ ì´ë¦„ ì‚¬ìš©

**ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:**
âœ… execution_order: [["{agents_str.split(', ')[0] if agents_str else 'mcp1'}", "{agents_str.split(', ')[1] if ', ' in agents_str else 'mcp2'}"]]  <- ì—ì´ì „íŠ¸ ì´ë¦„ ì‚¬ìš©
âœ… execution_order: [["{agents_str.split(', ')[0] if agents_str else 'mcp1'}"]]  <- ì—ì´ì „íŠ¸ ì´ë¦„ ì‚¬ìš©

**ì¤‘ìš” ì›ì¹™:**
1. ì§ˆë¬¸ì´ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ í•„ìš”ë¡œ í•˜ë©´ **ì‹¤í–‰ ìˆœì„œ**ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ê²°ì •
2. **ë³‘ë ¬ ì‹¤í–‰ì´ ìœ ë¦¬í•œ ê²½ìš° ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ë™ì‹œì— ì‹¤í–‰**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
3. **ë‚˜ì¤‘ ì—ì´ì „íŠ¸ê°€ ì´ì „ ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ í™œìš©í•´ì•¼ í•˜ë©´ ì˜ì¡´ì„±ì„ ëª…ì‹œí•˜ì—¬ ìˆœì°¨ ì‹¤í–‰**
4. ì¼ë°˜ì ì¸ ëŒ€í™”ëŠ” ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ì§€ ì•ŠìŒ (execution_order: [])

**ë³‘ë ¬ vs ìˆœì°¨ ì‹¤í–‰ íŒë‹¨ ê¸°ì¤€:**

ğŸ”€ **ë³‘ë ¬ ì‹¤í–‰ (ë™ì‹œì— ë…ë¦½ì ìœ¼ë¡œ ê²€ìƒ‰):**
- ë‘ ì—ì´ì „íŠ¸ì˜ ì‘ì—…ì´ **ì„œë¡œ ë…ë¦½ì **ì¼ ë•Œ
- í•œ ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ê°€ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì…ë ¥ìœ¼ë¡œ í•„ìš”í•˜ì§€ ì•Šì„ ë•Œ
- ì˜ˆ: "12ëŒ€ ì¤‘ê³¼ì‹¤ì€ ë­ì•¼?" â†’ ë²•ë¥  ì¡°ë¬¸ê³¼ íŒë¡€ë¥¼ ë™ì‹œì— ê²€ìƒ‰ ê°€ëŠ¥
  - execution_order: [["agent1", "agent2"]]
  - ë‘ ê²€ìƒ‰ì´ ì„œë¡œ ë…ë¦½ì ì„

â­ï¸ **ìˆœì°¨ ì‹¤í–‰ (ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ ë‘ ë²ˆì§¸ê°€ í™œìš©):**
- ë‚˜ì¤‘ ì—ì´ì „íŠ¸ê°€ **ì´ì „ ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¥¼ ì°¸ê³ **í•´ì•¼ í•  ë•Œ
- "ì°¾ì•„ë³´ê³  ~í•´ì¤˜", "ê²€ìƒ‰í•œ í›„ ~í•´ì¤˜", "ë°”íƒ•ìœ¼ë¡œ ~í•´ì¤˜" ê°™ì€ í‘œí˜„ì´ ìˆì„ ë•Œ
- ì˜ˆ: "ìµœê·¼ ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜ ì‚¬ë¡€ë¥¼ ì°¾ì•„ë³´ê³ , í•´ë‹¹ ë²• ì¡°í•­ì„ ì•Œë ¤ì¤˜"
  - execution_order: [["agent1"], ["agent2"]]
  - agent2ëŠ” agent1ì˜ ê²°ê³¼(ìœ„ë°˜ ì‚¬ë¡€)ë¥¼ ë³´ê³  ê´€ë ¨ ë²• ì¡°í•­ì„ ê²€ìƒ‰í•´ì•¼ í•¨
  - dependencies: {{"agent2": "agent1ì—ì„œ ì°¾ì€ ìœ„ë°˜ ì‚¬ë¡€ë¥¼ ë¶„ì„í•˜ì—¬ í•´ë‹¹ ë²• ì¡°í•­ ê²€ìƒ‰"}}

**ì‘ë‹µ í˜•ì‹ (JSON):**
{{
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
  "question_type": "single|multiple|parallel|general",
  "execution_order": [["agent_name1"], ["agent_name2", "agent_name3"]],
  "queries": {{
    "agent_name1": "í•´ë‹¹ ì—ì´ì „íŠ¸ì—ê²Œ í•  êµ¬ì²´ì ì¸ ì§ˆë¬¸",
    "agent_name2": "í•´ë‹¹ ì—ì´ì „íŠ¸ì—ê²Œ í•  êµ¬ì²´ì ì¸ ì§ˆë¬¸"
  }},
  "dependencies": {{
    "agent_name": "ì´ì „ ì—ì´ì „íŠ¸ ê²°ê³¼ í™œìš© ë°©ë²• (ì„ íƒì‚¬í•­)"
  }},
  "analysis": "ì§ˆë¬¸ ë¶„ì„ ë° ì‹¤í–‰ ìˆœì„œ(ìˆœì°¨/ë³‘ë ¬) ê²°ì • ì´ìœ "
}}

**execution_order ì‘ì„± ê·œì¹™:**
âš ï¸ CRITICAL: execution_orderì—ëŠ” ë°˜ë“œì‹œ ì‹¤ì œ ì—ì´ì „íŠ¸ ì´ë¦„ë§Œ ì‚¬ìš©í•˜ì„¸ìš”!
ì‚¬ìš© ê°€ëŠ¥: {agents_str}
ì‚¬ìš© ê¸ˆì§€: ë„êµ¬ ì´ë¦„ (law-search, precedent-search ë“±)

**í˜•ì‹ ì˜ˆì‹œ:**
- `[["{available_agents[0] if available_agents else 'mcp1'}"]]`: ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
- `[["{available_agents[0] if available_agents else 'mcp1'}"], ["{available_agents[1] if len(available_agents) > 1 else 'mcp2'}"]]`: ìˆœì°¨ ì‹¤í–‰
- `[["{available_agents[0] if available_agents else 'mcp1'}", "{available_agents[1] if len(available_agents) > 1 else 'mcp2'}"]]`: ë³‘ë ¬ ì‹¤í–‰
- `[]`: ì¼ë°˜ ëŒ€í™” (ì—ì´ì „íŠ¸ ë¯¸í˜¸ì¶œ)

**êµ¬ì²´ì ì¸ ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤:**

1ï¸âƒ£ **ë³‘ë ¬ ì‹¤í–‰ ì˜ˆì‹œ:**
ì§ˆë¬¸: "12ëŒ€ ì¤‘ê³¼ì‹¤ì´ ë­ì•¼?"
ë¶„ì„: ë²•ë¥  ì¡°ë¬¸ê³¼ íŒë¡€ë¥¼ ë™ì‹œì— ê²€ìƒ‰ ê°€ëŠ¥ (ë…ë¦½ì )
```json
{{
  "question_type": "parallel",
  "execution_order": [["{available_agents[0] if available_agents else 'mcp1'}", "{available_agents[1] if len(available_agents) > 1 else 'mcp2'}"]],
  "queries": {{
    "{available_agents[0] if available_agents else 'mcp1'}": "12ëŒ€ ì¤‘ê³¼ì‹¤ì˜ ë²•ë¥ ì  ì •ì˜ë¥¼ ê²€ìƒ‰",
    "{available_agents[1] if len(available_agents) > 1 else 'mcp2'}": "12ëŒ€ ì¤‘ê³¼ì‹¤ ê´€ë ¨ íŒë¡€ë¥¼ ê²€ìƒ‰"
  }},
  "dependencies": {{}},
  "analysis": "ë²•ë¥  ì¡°ë¬¸ê³¼ íŒë¡€ëŠ” ë…ë¦½ì ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•˜ë¯€ë¡œ ë³‘ë ¬ ì‹¤í–‰"
}}
```

2ï¸âƒ£ **ìˆœì°¨ ì‹¤í–‰ ì˜ˆì‹œ (ì˜ì¡´ì„± ìˆìŒ):**
ì§ˆë¬¸: "ìµœê·¼ ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜ ì‚¬ë¡€ë¥¼ ì°¾ì•„ë³´ê³ , í•´ë‹¹ ë²• ì¡°í•­ì„ ì•Œë ¤ì¤˜"
ë¶„ì„: ì²« ë²ˆì§¸ë¡œ ì‚¬ë¡€ ê²€ìƒ‰ â†’ ê·¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²• ì¡°í•­ ê²€ìƒ‰ (ì˜ì¡´ì )
```json
{{
  "question_type": "multiple",
  "execution_order": [["{available_agents[0] if available_agents else 'mcp1'}"], ["{available_agents[1] if len(available_agents) > 1 else 'mcp2'}"]],
  "queries": {{
    "{available_agents[0] if available_agents else 'mcp1'}": "ìµœê·¼ ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜ ì‚¬ë¡€ë¥¼ ê²€ìƒ‰",
    "{available_agents[1] if len(available_agents) > 1 else 'mcp2'}": "ìœ„ë°˜ ì‚¬ë¡€ì— í•´ë‹¹í•˜ëŠ” ê·¼ë¡œê¸°ì¤€ë²• ì¡°í•­ì„ ê²€ìƒ‰"
  }},
  "dependencies": {{
    "{available_agents[1] if len(available_agents) > 1 else 'mcp2'}": "ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ê°€ ì°¾ì€ ìœ„ë°˜ ì‚¬ë¡€ë¥¼ ë¶„ì„í•˜ì—¬ í•´ë‹¹ë˜ëŠ” ë²• ì¡°í•­ ê²€ìƒ‰"
  }},
  "analysis": "ì‚¬ë¡€ë¥¼ ë¨¼ì € ì°¾ì€ í›„, ê·¸ ì‚¬ë¡€ì— í•´ë‹¹í•˜ëŠ” ë²• ì¡°í•­ì„ ê²€ìƒ‰í•´ì•¼ í•˜ë¯€ë¡œ ìˆœì°¨ ì‹¤í–‰"
}}
```"""
        super().__init__(
            name="QuestionUnderstandingAgent",
            role="ì§ˆë¬¸ ì´í•´ ë° ë¼ìš°íŒ…",
            system_prompt=system_prompt,
            aoai_wrapper=aoai_wrapper
        )


class ToolBasedAgent(SpecializedAgent):
    """ë„êµ¬ ê¸°ë°˜ ì „ë¬¸ ì—ì´ì „íŠ¸ (ë²”ìš©)"""

    def __init__(self, name: str, role: str, aoai_wrapper: AzureOpenAIWrapper, tools: List[BaseTool]):
        system_prompt = f"""ë‹¹ì‹ ì€ {role} ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
í•„ìš”ì‹œ ì œê³µëœ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {len(tools)}ê°œ"""
        super().__init__(
            name=name,
            role=role,
            system_prompt=system_prompt,
            aoai_wrapper=aoai_wrapper
        )
        self.tools = tools

    async def process_with_tools(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬"""
        tools_for_openai = []
        for tool in self.tools:
            tool_name = getattr(tool, 'name', type(tool).__name__)
            tool_description = getattr(tool, 'description', '')
            tool_input_schema = getattr(tool, 'input_schema', None) or {"type": "object", "properties": {}}
            tools_for_openai.append({
                "type": "function",
                "function": {
                    "name": tool_name,
                    "description": tool_description or "",
                    "parameters": tool_input_schema,
                },
            })

        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_input}
        ]

        if context:
            context_str = f"\n\n[Context]\n{json.dumps(context, indent=2, ensure_ascii=False)}"
            messages[-1]["content"] += context_str

        max_iterations = 10
        for iteration in range(max_iterations):
            try:
                response = self.aoai_wrapper.chat_completion(messages, tools=tools_for_openai, stream=False)
                choice = response.choices[0].message

                if not getattr(choice, "tool_calls", None):
                    return AgentResponse(
                        content=choice.content or "",
                        metadata={"iterations": iteration + 1},
                        success=True,
                        agent_name=self.name
                    )

                print(f"  ğŸ”§ [{self.name}] Tool calls: {len(choice.tool_calls)}", flush=True)
                tool_results = []

                for tc in choice.tool_calls:
                    tool_name = tc.function.name
                    args = json.loads(tc.function.arguments) if tc.function.arguments else {}

                    for tool in self.tools:
                        current_tool_name = getattr(tool, 'name', type(tool).__name__)
                        if current_tool_name == tool_name:
                            try:
                                from google.adk.models import LlmRequest
                                class DummyToolContext:
                                    def __init__(self):
                                        self.llm_request = LlmRequest(contents=[])

                                tool_context = DummyToolContext()
                                result = await tool.run_async(args=args, tool_context=tool_context)
                                tool_results.append({
                                    "tool_call_id": tc.id,
                                    "content": str(result),
                                })
                                print(f"    âœ… Tool {tool_name} executed", flush=True)
                                break
                            except Exception as e:
                                tool_results.append({
                                    "tool_call_id": tc.id,
                                    "content": f"Error: {str(e)}",
                                })
                                break

                messages.append({
                    "role": "assistant",
                    "content": choice.content or "",
                    "tool_calls": [tc.model_dump() for tc in choice.tool_calls],
                })
                for tr in tool_results:
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tr["tool_call_id"],
                        "content": tr["content"],
                    })

            except Exception as e:
                return AgentResponse(
                    content=f"ì—ëŸ¬ ë°œìƒ: {str(e)}",
                    metadata={"error": str(e), "iteration": iteration},
                    success=False,
                    agent_name=self.name
                )

        return AgentResponse(
            content="ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬",
            metadata={"iterations": max_iterations},
            success=False,
            agent_name=self.name
        )


class MultiAgentOrchestrator:
    """ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - ë™ì  ì—ì´ì „íŠ¸ ê´€ë¦¬"""

    def __init__(self):
        self.servers: Dict[str, MCPServerConnection] = {}
        self.all_tools: List[BaseTool] = []
        self.aoai_wrapper: Optional[AzureOpenAIWrapper] = None

        self.question_agent: Optional[QuestionUnderstandingAgent] = None
        self.specialist_agents: Dict[str, ToolBasedAgent] = {}  # MCP ì„œë²„ë³„ ì—ì´ì „íŠ¸

    def _normalize_url(self, url: str) -> str:
        """URL ì •ê·œí™”"""
        return url if url.endswith("/") else url + "/"

    def _prefix_tool(self, tool: BaseTool, prefix: str) -> BaseTool:
        """ë„êµ¬ ì´ë¦„ì— prefix ì¶”ê°€"""
        class PrefixedTool(tool.__class__):
            @property
            def name(self):
                original = getattr(super(), "name", getattr(tool, "name", type(tool).__name__))
                return f"{prefix}__{original}"

        wrapped = PrefixedTool.__new__(PrefixedTool)
        wrapped.__dict__ = tool.__dict__.copy()
        return wrapped

    async def connect_mcp_server(self, server_name: str, base_url: str, auth_bearer: str = "") -> MCPServerConnection:
        """MCP ì„œë²„ ì—°ê²° ë° ì—ì´ì „íŠ¸ ìë™ ìƒì„±"""
        base_url = self._normalize_url(base_url)
        headers = {}
        if auth_bearer:
            headers["Authorization"] = f"Bearer {auth_bearer}"
        try:
            conn_params = StreamableHTTPConnectionParams(
                url=base_url,
                headers=headers if headers else None,
                timeout=10.0,
                sse_read_timeout=300.0,
            )
            toolset = McpToolset(connection_params=conn_params)
            tools = await toolset.get_tools()
            connection = MCPServerConnection(
                name=server_name,
                toolset=toolset
            )
            self.servers[server_name] = connection

            # ë„êµ¬ì— prefix ì¶”ê°€
            prefixed_tools = []
            for tool in tools:
                prefixed_tool = self._prefix_tool(tool, server_name)
                prefixed_tools.append(prefixed_tool)
                self.all_tools.append(prefixed_tool)

            # ì—ì´ì „íŠ¸ ìë™ ìƒì„± (ì´ˆê¸°í™” í›„)
            # initialize_agentsì—ì„œ ì²˜ë¦¬

            return connection
        except Exception as e:
            error_msg = str(e)
            print(f"\n[Error] Failed to connect to {server_name}: {error_msg}")
            print(f" URL: {base_url}")
            if server_name in self.servers:
                del self.servers[server_name]
            raise RuntimeError(f"Failed to connect to MCP server {server_name} at {base_url}: {error_msg}") from e

    def initialize_agents(self):
        """ê°œë³„ íŠ¹í™” ì—ì´ì „íŠ¸ë“¤ì„ ë™ì ìœ¼ë¡œ ì´ˆê¸°í™”"""
        self.aoai_wrapper = AzureOpenAIWrapper(
            api_key=os.environ["AZURE_OPENAI_API_KEY"],
            api_version=os.environ["AZURE_OPENAI_API_VERSION"],
            azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
            deployment=os.environ["AZURE_OPENAI_DEPLOYMENT"],
        )

        # ê° ì„œë²„ë³„ ë„êµ¬ ì •ë³´ ìˆ˜ì§‘
        agent_tools_info = {}
        for server_name in self.servers.keys():
            server_tools = [tool for tool in self.all_tools if getattr(tool, 'name', '').startswith(f'{server_name}__')]
            tool_names = [getattr(tool, 'name', '').replace(f'{server_name}__', '') for tool in server_tools]
            agent_tools_info[server_name] = tool_names

        # Agent A ì´ˆê¸°í™” (ë¼ìš°íŒ… ì—ì´ì „íŠ¸) - ë„êµ¬ ì •ë³´ í¬í•¨
        available_agents = list(self.servers.keys())
        self.question_agent = QuestionUnderstandingAgent(self.aoai_wrapper, available_agents, agent_tools_info)

        # ê° MCP ì„œë²„ë³„ë¡œ ì—ì´ì „íŠ¸ ìë™ ìƒì„±
        print(f"\nâœ… ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ:")
        print(f"   â€¢ {self.question_agent.name}: {self.question_agent.role}")

        for server_name in self.servers.keys():
            # í•´ë‹¹ ì„œë²„ì˜ ë„êµ¬ë§Œ í•„í„°ë§
            server_tools = [tool for tool in self.all_tools if getattr(tool, 'name', '').startswith(f'{server_name}__')]

            # ì—ì´ì „íŠ¸ ìƒì„±
            agent = ToolBasedAgent(
                name=f"{server_name.upper()}Agent",
                role=f"{server_name} ì „ë¬¸ ì„œë¹„ìŠ¤",
                aoai_wrapper=self.aoai_wrapper,
                tools=server_tools
            )
            self.specialist_agents[server_name] = agent
            print(f"   â€¢ {agent.name}: {agent.role} (ë„êµ¬ {len(server_tools)}ê°œ)")
            # ë„êµ¬ ëª©ë¡ ì¶œë ¥
            for tool in server_tools:
                tool_name = getattr(tool, 'name', '')
                print(f"      - {tool_name}")
                # tool_description = getattr(tool, 'description', '')
                # print(f"      - {tool_name} {tool_description}")

    async def close_all_servers(self):
        """ëª¨ë“  MCP ì„œë²„ ì—°ê²° ì¢…ë£Œ"""
        for server_name, server in list(self.servers.items()):
            try:
                if server.toolset:
                    await asyncio.wait_for(server.toolset.close(), timeout=5.0)
                    print(f"âœ“ Closed {server_name}")
            except asyncio.TimeoutError:
                print(f"âš ï¸  Timeout closing server {server_name}")
            except asyncio.CancelledError:
                print(f"âš ï¸  Cancelled while closing server {server_name}")
            except Exception as e:
                print(f"âš ï¸  Error closing server {server_name}: {e}")
        self.servers.clear()
        self.all_tools.clear()
        self.specialist_agents.clear()


async def initialize_multi_agent() -> MultiAgentOrchestrator:
    """ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - ë™ì  MCP ì„œë²„ ì—°ê²°"""
    orchestrator = MultiAgentOrchestrator()
    connected_servers = []

    try:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ MCP ì„œë²„ ëª©ë¡ ë™ì  ë¡œë“œ
        server_index = 1
        while True:
            url_key = f"MCP_SERVER_{server_index}_URL"
            bearer_key = f"MCP_SERVER_{server_index}_AUTH_BEARER"
            name_key = f"MCP_SERVER_{server_index}_NAME"

            server_url = os.environ.get(url_key, "")
            if not server_url:
                break

            server_bearer = os.environ.get(bearer_key, "")
            server_name = os.environ.get(name_key, f"mcp{server_index}")

            print(f"Connecting to MCP Server '{server_name}': {server_url}")
            try:
                await orchestrator.connect_mcp_server(server_name, server_url, server_bearer)
                print(f"âœ“ Connected to {server_name}")
                connected_servers.append(server_name)
            except Exception as e:
                print(f"âœ— Failed to connect to {server_name}: {e}")

            server_index += 1

        if not connected_servers:
            raise RuntimeError("No MCP servers connected. Check your .env configuration.")

        print(f"\nâœ… Connected to {len(connected_servers)} MCP server(s): {', '.join(connected_servers)}")
        print("\nInitializing Multi-Agent System...")
        orchestrator.initialize_agents()
        print(f"âœ“ Multi-Agent System initialized with {len(orchestrator.all_tools)} total tools\n")

        return orchestrator

    except Exception as e:
        raise RuntimeError(f"Failed to initialize multi-agent system: {e}") from e


async def run_multi_agent_conversation(orchestrator: MultiAgentOrchestrator, user_query: str) -> str:
    """ë©€í‹° ì—ì´ì „íŠ¸ ëŒ€í™” ì‹¤í–‰"""

    print(f"\n{'='*70}")
    print(f"ğŸ¤– Multi-Agent Processing Pipeline")
    print(f"{'='*70}\n")

    # Step 1: Agent A - ì§ˆë¬¸ ë¶„ì„
    print(f"ğŸ“‹ [Step 1] Agent A: ì§ˆë¬¸ ë¶„ì„ ë° ë¼ìš°íŒ…")
    print(f"{'â”€'*70}")

    step1_start = time.time()
    question_response = await orchestrator.question_agent.process(user_query)
    step1_time = time.time() - step1_start

    if not question_response.success:
        print(f"âŒ ì§ˆë¬¸ ë¶„ì„ ì‹¤íŒ¨: {question_response.content}")
        return question_response.content

    print(f"âœ… ë¶„ì„ ì™„ë£Œ ({step1_time:.2f}ì´ˆ)")
    print(f"\n{question_response.content}\n")

    # JSON íŒŒì‹±
    try:
        content = question_response.content
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()

        analysis = json.loads(content)
        execution_order = analysis.get("execution_order", [])
        question_type = analysis.get("question_type", "general")
        queries = analysis.get("queries", {})
        dependencies = analysis.get("dependencies", {})

        print(f"ğŸ¯ íŒë‹¨ ê²°ê³¼:")
        print(f"   ì§ˆë¬¸ ìœ í˜•: {question_type}")

        # execution_orderë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥ (ë³‘ë ¬ì€ ê´„í˜¸ë¡œ, ìˆœì°¨ëŠ” í™”ì‚´í‘œë¡œ)
        if execution_order:
            execution_plan_str = " â†’ ".join([
                f"({', '.join(group)})" if len(group) > 1 else group[0]
                for group in execution_order
            ])
            print(f"   ì‹¤í–‰ ìˆœì„œ: {execution_plan_str}")
        else:
            print(f"   ì‹¤í–‰ ìˆœì„œ: none")

        # ê° ì—ì´ì „íŠ¸ë³„ ì§ˆë¬¸ ì¶œë ¥
        if queries:
            flat_order = [agent for group in execution_order for agent in group]
            for agent in flat_order:
                if agent in queries:
                    print(f"   - {agent}: {queries[agent]}")
                    if agent in dependencies:
                        print(f"      â””â”€ ì˜ì¡´ì„±: {dependencies[agent]}")
        print()

    except json.JSONDecodeError:
        print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ ì²˜ë¦¬ë¡œ ì§„í–‰\n")
        execution_order = []
        queries = {}
        dependencies = {}

    # Step 2: ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ ìˆœì°¨ ì‹¤í–‰
    if not execution_order:
        # ì¼ë°˜ ì§ˆë¬¸ - Agent Aê°€ ì§ì ‘ ë‹µë³€
        print(f"ğŸ’¬ [Final Answer] Agent A ì§ì ‘ ë‹µë³€")
        print(f"{'â”€'*70}\n")

        try:
            messages = [
                {"role": "system", "content": """ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""},
                {"role": "user", "content": user_query}
            ]

            stream_start = time.time()
            stream_response = orchestrator.aoai_wrapper.chat_completion(messages, stream=True)

            collected_content = ""
            for chunk in stream_response:
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        print(delta.content, end="", flush=True)
                        collected_content += delta.content

            stream_time = time.time() - stream_start
            print(f"\n\nâ±ï¸  ë‹µë³€ ìƒì„± ì‹œê°„: {stream_time:.2f}ì´ˆ")

            return collected_content

        except Exception as e:
            print(f"\nâš ï¸  ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return question_response.content

    agent_results = {}
    previous_results = []
    step_num = 2

    # execution_orderë¥¼ ê·¸ë£¹ë³„ë¡œ ì‹¤í–‰ (ê° ê·¸ë£¹ ë‚´ë¶€ëŠ” ë³‘ë ¬, ê·¸ë£¹ ê°„ì€ ìˆœì°¨)
    for group_idx, agent_group in enumerate(execution_order):
        if not agent_group:
            continue

        # ë‹¨ì¼ ì—ì´ì „íŠ¸ (ìˆœì°¨ ì‹¤í–‰)
        if len(agent_group) == 1:
            agent_name = agent_group[0]
            if agent_name not in orchestrator.specialist_agents:
                print(f"âš ï¸  ì—ì´ì „íŠ¸ '{agent_name}' not found, skipping...")
                continue

            specialist_agent = orchestrator.specialist_agents[agent_name]
            print(f"ğŸ”§ [Step {step_num}] {specialist_agent.name} ì²˜ë¦¬ (ìˆœì°¨)")
            print(f"{'â”€'*70}")

            query = queries.get(agent_name, user_query)
            dependency = dependencies.get(agent_name, "")

            print(f"ì§ˆë¬¸: {query}")
            if dependency and previous_results:
                print(f"ì˜ì¡´ì„±: {dependency}")
            print()

            step_start = time.time()
            context = {
                "original_query": user_query,
                "analysis": question_response.content,
                "structured_query": query,
            }
            if previous_results:
                context["previous_agent_results"] = previous_results
                if dependency:
                    context["dependency_instruction"] = dependency

            response = await specialist_agent.process_with_tools(query, context)
            step_time = time.time() - step_start

            if response.success:
                print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ ({step_time:.2f}ì´ˆ)\n")
                result_info = {
                    "agent": specialist_agent.name,
                    "agent_name": agent_name,
                    "query": query,
                    "response": response.content,
                    "time": step_time
                }
                agent_results[agent_name] = result_info
                previous_results.append(result_info)
            else:
                print(f"\nâŒ ì²˜ë¦¬ ì‹¤íŒ¨: {response.content}\n")

        # ì—¬ëŸ¬ ì—ì´ì „íŠ¸ (ë³‘ë ¬ ì‹¤í–‰)
        else:
            print(f"ğŸš€ [Step {step_num}] {len(agent_group)}ê°œ ì—ì´ì „íŠ¸ ë³‘ë ¬ ì²˜ë¦¬: {', '.join(agent_group)}")
            print(f"{'â”€'*70}")

            tasks = []
            task_agent_names = []

            for agent_name in agent_group:
                if agent_name not in orchestrator.specialist_agents:
                    print(f"âš ï¸  ì—ì´ì „íŠ¸ '{agent_name}' not found, skipping...")
                    continue

                specialist_agent = orchestrator.specialist_agents[agent_name]
                query = queries.get(agent_name, user_query)
                dependency = dependencies.get(agent_name, "")

                print(f"  - {specialist_agent.name}")
                print(f"    ì§ˆë¬¸: {query}")
                if dependency and previous_results:
                    print(f"    ì˜ì¡´ì„±: {dependency}")

                context = {
                    "original_query": user_query,
                    "analysis": question_response.content,
                    "structured_query": query,
                }
                if previous_results:
                    context["previous_agent_results"] = previous_results
                    if dependency:
                        context["dependency_instruction"] = dependency

                tasks.append(specialist_agent.process_with_tools(query, context))
                task_agent_names.append(agent_name)

            if tasks:
                print()
                step_start = time.time()
                parallel_responses = await asyncio.gather(*tasks)
                step_time = time.time() - step_start

                print(f"âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ ({step_time:.2f}ì´ˆ)\n")

                # ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ì €ì¥
                for agent_name, response in zip(task_agent_names, parallel_responses):
                    if response.success:
                        result_info = {
                            "agent": response.agent_name,
                            "agent_name": agent_name,
                            "query": queries.get(agent_name, user_query),
                            "response": response.content,
                            "time": step_time  # ë³‘ë ¬ ì‹¤í–‰ì€ ì „ì²´ ì‹œê°„ ì‚¬ìš©
                        }
                        agent_results[agent_name] = result_info
                        previous_results.append(result_info)
                        print(f"  âœ“ {response.agent_name}: ì„±ê³µ")
                    else:
                        print(f"  âœ— {response.agent_name}: ì‹¤íŒ¨ - {response.content}")
                print()

        step_num += 1

    if not agent_results:
        return question_response.content

    # Step 3: Agent A - ê²°ê³¼ í†µí•©
    print(f"ğŸ”„ [Step {step_num}] Agent A: ê²°ê³¼ í†µí•© ë° ìµœì¢… ë‹µë³€ ìƒì„±")
    print(f"{'â”€'*70}\n")

    try:
        expert_answers = ""
        # execution_orderë¥¼ flatí•˜ê²Œ ë§Œë“¤ì–´ì„œ ìˆœì„œëŒ€ë¡œ ì¶œë ¥
        flat_execution_order = [agent for group in execution_order for agent in group]
        for i, agent_name in enumerate(flat_execution_order, 1):
            if agent_name in agent_results:
                result = agent_results[agent_name]
                expert_answers += f"\n\n[{i}ë‹¨ê³„: {result['agent']}ì˜ ë‹µë³€]\nì§ˆë¬¸: {result['query']}\në‹µë³€: {result['response']}"

        messages = [
            {"role": "system", "content": """ë‹¹ì‹ ì€ ì—¬ëŸ¬ ì „ë¬¸ê°€ì˜ ë‹µë³€ì„ í†µí•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ëŠ” ì½”ë””ë„¤ì´í„°ì…ë‹ˆë‹¤.
ê° ì „ë¬¸ê°€ì˜ ë‹µë³€ì„ ì‹¤í–‰ ìˆœì„œëŒ€ë¡œ ì¢…í•©í•˜ì—¬ ëª…í™•í•˜ê³  ì²´ê³„ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."""},
            {"role": "user", "content": f"""ì›ë³¸ ì§ˆë¬¸: {user_query}

ì „ë¬¸ê°€ ë‹µë³€ë“¤ (ì‹¤í–‰ ìˆœì„œ):
{expert_answers}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""}
        ]

        stream_start = time.time()
        stream_response = orchestrator.aoai_wrapper.chat_completion(messages, stream=True)

        collected_content = ""
        for chunk in stream_response:
            if chunk.choices and len(chunk.choices) > 0:
                delta = chunk.choices[0].delta
                if hasattr(delta, 'content') and delta.content:
                    print(delta.content, end="", flush=True)
                    collected_content += delta.content

        stream_time = time.time() - stream_start
        print(f"\n\nâ±ï¸  í†µí•© ë‹µë³€ ìƒì„± ì‹œê°„: {stream_time:.2f}ì´ˆ")

        return collected_content

    except Exception as e:
        print(f"\nâš ï¸  í†µí•© ì‹¤íŒ¨: {e}")
        return "\n\n".join([f"[{r['agent']}]\n{r['response']}" for r in agent_results.values()])


async def main():
    print("="*70)
    print("ğŸ¤– Dynamic Multi-Agent System")
    print("="*70)

    orchestrator = None
    try:
        orchestrator = await initialize_multi_agent()
        print("\nâœ… Multi-Agent System is ready!")
        print("Type 'quit' or 'exit' to stop.\n")

        while True:
            q = input("\nğŸ§‘ You> ").strip()
            if q.lower() in {"quit", "exit", "q"}:
                break
            if not q:
                continue

            try:
                conversation_start = time.time()
                ans = await run_multi_agent_conversation(orchestrator, q)
                total_time = time.time() - conversation_start
                print(f"\nâ±ï¸  ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
            except Exception as e:
                print(f"\nâŒ [Error] {e}")
                import traceback
                traceback.print_exc()

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Interrupted by user.")
    except Exception as e:
        print(f"\nâŒ [Fatal Error] {e}")
        import traceback
        traceback.print_exc()
    finally:
        if orchestrator:
            print("\nğŸ”Œ Closing all MCP server connections...")
            try:
                await orchestrator.close_all_servers()
                print("âœ“ All connections closed.")
            except Exception as e:
                print(f"âš ï¸  Error during cleanup: {e}")


if __name__ == "__main__":
    asyncio.run(main())

